{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      6    2010        WD         Normal  \n",
       "1   12500      6    2010        WD         Normal  \n",
       "2       0      3    2010        WD         Normal  \n",
       "3       0      6    2010        WD         Normal  \n",
       "4       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 0 to 1458\n",
      "Data columns (total 80 columns):\n",
      "Id               1459 non-null int64\n",
      "MSSubClass       1459 non-null int64\n",
      "MSZoning         1455 non-null object\n",
      "LotFrontage      1232 non-null float64\n",
      "LotArea          1459 non-null int64\n",
      "Street           1459 non-null object\n",
      "Alley            107 non-null object\n",
      "LotShape         1459 non-null object\n",
      "LandContour      1459 non-null object\n",
      "Utilities        1457 non-null object\n",
      "LotConfig        1459 non-null object\n",
      "LandSlope        1459 non-null object\n",
      "Neighborhood     1459 non-null object\n",
      "Condition1       1459 non-null object\n",
      "Condition2       1459 non-null object\n",
      "BldgType         1459 non-null object\n",
      "HouseStyle       1459 non-null object\n",
      "OverallQual      1459 non-null int64\n",
      "OverallCond      1459 non-null int64\n",
      "YearBuilt        1459 non-null int64\n",
      "YearRemodAdd     1459 non-null int64\n",
      "RoofStyle        1459 non-null object\n",
      "RoofMatl         1459 non-null object\n",
      "Exterior1st      1458 non-null object\n",
      "Exterior2nd      1458 non-null object\n",
      "MasVnrType       1443 non-null object\n",
      "MasVnrArea       1444 non-null float64\n",
      "ExterQual        1459 non-null object\n",
      "ExterCond        1459 non-null object\n",
      "Foundation       1459 non-null object\n",
      "BsmtQual         1415 non-null object\n",
      "BsmtCond         1414 non-null object\n",
      "BsmtExposure     1415 non-null object\n",
      "BsmtFinType1     1417 non-null object\n",
      "BsmtFinSF1       1458 non-null float64\n",
      "BsmtFinType2     1417 non-null object\n",
      "BsmtFinSF2       1458 non-null float64\n",
      "BsmtUnfSF        1458 non-null float64\n",
      "TotalBsmtSF      1458 non-null float64\n",
      "Heating          1459 non-null object\n",
      "HeatingQC        1459 non-null object\n",
      "CentralAir       1459 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1459 non-null int64\n",
      "2ndFlrSF         1459 non-null int64\n",
      "LowQualFinSF     1459 non-null int64\n",
      "GrLivArea        1459 non-null int64\n",
      "BsmtFullBath     1457 non-null float64\n",
      "BsmtHalfBath     1457 non-null float64\n",
      "FullBath         1459 non-null int64\n",
      "HalfBath         1459 non-null int64\n",
      "BedroomAbvGr     1459 non-null int64\n",
      "KitchenAbvGr     1459 non-null int64\n",
      "KitchenQual      1458 non-null object\n",
      "TotRmsAbvGrd     1459 non-null int64\n",
      "Functional       1457 non-null object\n",
      "Fireplaces       1459 non-null int64\n",
      "FireplaceQu      729 non-null object\n",
      "GarageType       1383 non-null object\n",
      "GarageYrBlt      1381 non-null float64\n",
      "GarageFinish     1381 non-null object\n",
      "GarageCars       1458 non-null float64\n",
      "GarageArea       1458 non-null float64\n",
      "GarageQual       1381 non-null object\n",
      "GarageCond       1381 non-null object\n",
      "PavedDrive       1459 non-null object\n",
      "WoodDeckSF       1459 non-null int64\n",
      "OpenPorchSF      1459 non-null int64\n",
      "EnclosedPorch    1459 non-null int64\n",
      "3SsnPorch        1459 non-null int64\n",
      "ScreenPorch      1459 non-null int64\n",
      "PoolArea         1459 non-null int64\n",
      "PoolQC           3 non-null object\n",
      "Fence            290 non-null object\n",
      "MiscFeature      51 non-null object\n",
      "MiscVal          1459 non-null int64\n",
      "MoSold           1459 non-null int64\n",
      "YrSold           1459 non-null int64\n",
      "SaleType         1458 non-null object\n",
      "SaleCondition    1459 non-null object\n",
      "dtypes: float64(11), int64(26), object(43)\n",
      "memory usage: 912.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21a53ad8dc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21a5443bfc8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(test.isnull(),cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "test['LotFrontage']=test['LotFrontage'].fillna(test['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['BsmtCond']=test['BsmtCond'].fillna(test['BsmtCond'].mode()[0])\n",
    "test['BsmtQual']=test['BsmtQual'].fillna(test['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['FireplaceQu']=test['FireplaceQu'].fillna(test['FireplaceQu'].mode()[0])\n",
    "test['GarageType']=test['GarageType'].fillna(test['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['GarageFinish']=test['GarageFinish'].fillna(test['GarageFinish'].mode()[0])\n",
    "test['GarageQual']=test['GarageQual'].fillna(test['GarageQual'].mode()[0])\n",
    "test['GarageCond']=test['GarageCond'].fillna(test['GarageCond'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['MasVnrType']=test['MasVnrType'].fillna(test['MasVnrType'].mode()[0])\n",
    "test['MasVnrArea']=test['MasVnrArea'].fillna(test['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['BsmtExposure']=test['BsmtExposure'].fillna(test['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['BsmtFinType2']=test['BsmtFinType2'].fillna(test['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>SaleType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RH</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>Rec</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RL</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RL</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RL</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RL</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSZoning Utilities Exterior1st Exterior2nd BsmtFinType1  BsmtFinSF1  \\\n",
       "0       RH    AllPub     VinylSd     VinylSd          Rec       468.0   \n",
       "1       RL    AllPub     Wd Sdng     Wd Sdng          ALQ       923.0   \n",
       "2       RL    AllPub     VinylSd     VinylSd          GLQ       791.0   \n",
       "3       RL    AllPub     VinylSd     VinylSd          GLQ       602.0   \n",
       "4       RL    AllPub     HdBoard     HdBoard          ALQ       263.0   \n",
       "\n",
       "   BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  BsmtFullBath  BsmtHalfBath KitchenQual  \\\n",
       "0       144.0      270.0        882.0           0.0           0.0          TA   \n",
       "1         0.0      406.0       1329.0           0.0           0.0          Gd   \n",
       "2         0.0      137.0        928.0           0.0           0.0          TA   \n",
       "3         0.0      324.0        926.0           0.0           0.0          Gd   \n",
       "4         0.0     1017.0       1280.0           0.0           0.0          Gd   \n",
       "\n",
       "  Functional  GarageCars  GarageArea SaleType  \n",
       "0        Typ         1.0       730.0       WD  \n",
       "1        Typ         1.0       312.0       WD  \n",
       "2        Typ         2.0       482.0       WD  \n",
       "3        Typ         2.0       470.0       WD  \n",
       "4        Typ         2.0       506.0       WD  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test.loc[:, test.isnull().any()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Utilities']=test['Utilities'].fillna(test['Utilities'].mode()[0])\n",
    "test['Exterior1st']=test['Exterior1st'].fillna(test['Exterior1st'].mode()[0])\n",
    "test['Exterior2nd']=test['Exterior2nd'].fillna(test['Exterior2nd'].mode()[0])\n",
    "test['BsmtFinType1']=test['BsmtFinType1'].fillna(test['BsmtFinType1'].mode()[0])\n",
    "test['BsmtFinSF1']=test['BsmtFinSF1'].fillna(test['BsmtFinSF1'].mean())\n",
    "test['BsmtFinSF2']=test['BsmtFinSF2'].fillna(test['BsmtFinSF2'].mean())\n",
    "test['BsmtUnfSF']=test['BsmtUnfSF'].fillna(test['BsmtUnfSF'].mean())\n",
    "test['TotalBsmtSF']=test['TotalBsmtSF'].fillna(test['TotalBsmtSF'].mean())\n",
    "test['BsmtFullBath']=test['BsmtFullBath'].fillna(test['BsmtFullBath'].mode()[0])\n",
    "test['BsmtHalfBath']=test['BsmtHalfBath'].fillna(test['BsmtHalfBath'].mode()[0])\n",
    "test['KitchenQual']=test['KitchenQual'].fillna(test['KitchenQual'].mode()[0])\n",
    "test['Functional']=test['Functional'].fillna(test['Functional'].mode()[0])\n",
    "test['GarageCars']=test['GarageCars'].fillna(test['GarageCars'].mean())\n",
    "test['GarageArea']=test['GarageArea'].fillna(test['GarageArea'].mean())\n",
    "test['SaleType']=test['SaleType'].fillna(test['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('formulatedtest.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features\n",
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1454</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0          856       854          0             3       706.0         0.0   \n",
       "1         1262         0          0             3       978.0         0.0   \n",
       "2          920       866          0             3       486.0         0.0   \n",
       "3          961       756          0             3       216.0         0.0   \n",
       "4         1145      1053          0             4       655.0         0.0   \n",
       "...        ...       ...        ...           ...         ...         ...   \n",
       "1454       546       546          0             3         0.0         0.0   \n",
       "1455       546       546          0             3       252.0         0.0   \n",
       "1456      1224         0          0             4      1224.0         0.0   \n",
       "1457       970         0          0             3       337.0         0.0   \n",
       "1458       996      1004          0             3       758.0         0.0   \n",
       "\n",
       "      BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  \\\n",
       "0              1.0           0.0      150.0              0  ...     0     0   \n",
       "1              0.0           1.0      284.0              0  ...     0     0   \n",
       "2              1.0           0.0      434.0              0  ...     0     0   \n",
       "3              1.0           0.0      540.0            272  ...     0     0   \n",
       "4              1.0           0.0      490.0              0  ...     0     0   \n",
       "...            ...           ...        ...            ...  ...   ...   ...   \n",
       "1454           0.0           0.0      546.0              0  ...     0     0   \n",
       "1455           0.0           0.0      294.0              0  ...     0     0   \n",
       "1456           1.0           0.0        0.0              0  ...     0     0   \n",
       "1457           0.0           1.0      575.0              0  ...     0     0   \n",
       "1458           0.0           0.0      238.0              0  ...     0     0   \n",
       "\n",
       "      Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1       1        0        0        0       0    1  0  \n",
       "1       1       1        0        0        0       0    1  0  \n",
       "2       1       1        0        0        0       0    1  0  \n",
       "3       1       0        0        0        0       1    0  0  \n",
       "4       1       1        0        0        0       0    1  0  \n",
       "...   ...     ...      ...      ...      ...     ...  ... ..  \n",
       "1454    1       1        0        0        0       0    0  0  \n",
       "1455    1       0        0        0        1       0    0  0  \n",
       "1456    1       0        0        0        0       1    0  0  \n",
       "1457    1       1        0        0        0       0    0  0  \n",
       "1458    1       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "3       961       756          0             3       216.0         0.0   \n",
       "4      1145      1053          0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  Typ  \\\n",
       "0           1.0           0.0      150.0              0  ...     0     0    1   \n",
       "1           0.0           1.0      284.0              0  ...     0     0    1   \n",
       "2           1.0           0.0      434.0              0  ...     0     0    1   \n",
       "3           1.0           0.0      540.0            272  ...     0     0    1   \n",
       "4           1.0           0.0      490.0              0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0  ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0  ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0  ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0  ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 175)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129051.695, 149433.58 , 196159.06 , ..., 169300.45 , 108080.62 ,\n",
       "       234994.47 ], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using xgboost\n",
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_con...\n",
       "                   iid='warn', n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=900, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=900, n_jobs=1, nthread=1, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, seed=0, silent=True, subsample=1,\n",
       "             tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre=regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(y_pre)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117275.625, 163568.39 , 188306.14 , ..., 181178.69 , 115435.21 ,\n",
       "       236526.36 ], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  del sys.path[0]\n",
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1137 samples, validate on 285 samples\n",
      "Epoch 1/1000\n",
      "1137/1137 [==============================] - 5s 4ms/step - loss: 151265.2471 - val_loss: 69738.0645\n",
      "Epoch 2/1000\n",
      "1137/1137 [==============================] - 2s 1ms/step - loss: 68800.2920 - val_loss: 64851.4057\n",
      "Epoch 3/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 63427.6128 - val_loss: 61965.6623\n",
      "Epoch 4/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 59651.5033 - val_loss: 59330.9831\n",
      "Epoch 5/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 56190.9432 - val_loss: 56846.8246\n",
      "Epoch 6/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 52902.6667 - val_loss: 54450.3629\n",
      "Epoch 7/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 49395.7783 - val_loss: 52313.6225\n",
      "Epoch 8/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 45969.3117 - val_loss: 51045.5101\n",
      "Epoch 9/1000\n",
      "1137/1137 [==============================] - 1s 454us/step - loss: 44077.4164 - val_loss: 48754.3163\n",
      "Epoch 10/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 41797.1267 - val_loss: 47170.5460\n",
      "Epoch 11/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 39471.1159 - val_loss: 46100.5379\n",
      "Epoch 12/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 38439.116 - 0s 389us/step - loss: 38399.7445 - val_loss: 45411.3931\n",
      "Epoch 13/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 37609.1546 - val_loss: 46939.2170\n",
      "Epoch 14/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 37423.5067 - val_loss: 45082.1095\n",
      "Epoch 15/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 36748.8939 - val_loss: 45304.6668\n",
      "Epoch 16/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 36601.4326 - val_loss: 45599.5936\n",
      "Epoch 17/1000\n",
      "1137/1137 [==============================] - 0s 424us/step - loss: 36467.5379 - val_loss: 45072.3414\n",
      "Epoch 18/1000\n",
      "1137/1137 [==============================] - 0s 410us/step - loss: 36477.1791 - val_loss: 45882.1686\n",
      "Epoch 19/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 36063.4262 - val_loss: 44934.9351\n",
      "Epoch 20/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 36073.0475 - val_loss: 45390.9813\n",
      "Epoch 21/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 36032.9266 - val_loss: 45268.3141\n",
      "Epoch 22/1000\n",
      "1137/1137 [==============================] - 0s 372us/step - loss: 35754.6559 - val_loss: 45201.4792\n",
      "Epoch 23/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 35726.5481 - val_loss: 45206.0927\n",
      "Epoch 24/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 35799.2001 - val_loss: 44988.6850\n",
      "Epoch 25/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 35707.8255 - val_loss: 44874.8366\n",
      "Epoch 26/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 35614.4054 - val_loss: 45146.0549\n",
      "Epoch 27/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 35909.4334 - val_loss: 45492.2747\n",
      "Epoch 28/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 35538.0910 - val_loss: 44841.2527\n",
      "Epoch 29/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 35598.6809 - val_loss: 44840.8581\n",
      "Epoch 30/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 35464.7588 - val_loss: 44941.8509\n",
      "Epoch 31/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 35030.9366 - val_loss: 44720.0943\n",
      "Epoch 32/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 35223.4470 - val_loss: 45355.1857\n",
      "Epoch 33/1000\n",
      "1137/1137 [==============================] - 1s 442us/step - loss: 35584.4472 - val_loss: 44622.3845\n",
      "Epoch 34/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 35067.3177 - val_loss: 44847.8501\n",
      "Epoch 35/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 35145.6250 - val_loss: 45002.6719\n",
      "Epoch 36/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 35295.4354 - val_loss: 44703.2213\n",
      "Epoch 37/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 35501.4728 - val_loss: 44628.8370\n",
      "Epoch 38/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 34814.0033 - val_loss: 45175.1850\n",
      "Epoch 39/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 35175.8342 - val_loss: 44646.0875\n",
      "Epoch 40/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 34487.3821 - val_loss: 44894.5077\n",
      "Epoch 41/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 35177.4367 - val_loss: 45524.8202\n",
      "Epoch 42/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 34690.6291 - val_loss: 46001.2339\n",
      "Epoch 43/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 34897.9733 - val_loss: 44809.7270\n",
      "Epoch 44/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 34892.5877 - val_loss: 44657.5156\n",
      "Epoch 45/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 34928.8983 - val_loss: 44505.7796\n",
      "Epoch 46/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 35104.9014 - val_loss: 44477.4233\n",
      "Epoch 47/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 34661.8251 - val_loss: 44532.1569\n",
      "Epoch 48/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 34560.9718 - val_loss: 45278.0769\n",
      "Epoch 49/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 35089.7628 - val_loss: 44429.1637\n",
      "Epoch 50/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: 34795.7644 - val_loss: 44638.6188\n",
      "Epoch 51/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 34320.9917 - val_loss: 44715.5425\n",
      "Epoch 52/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 34163.5612 - val_loss: 44680.9766\n",
      "Epoch 53/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 33988.3752 - val_loss: 44519.1482\n",
      "Epoch 54/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 34529.6544 - val_loss: 44624.1627\n",
      "Epoch 55/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 34566.9180 - val_loss: 44510.1899\n",
      "Epoch 56/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 34413.4198 - val_loss: 44896.7200\n",
      "Epoch 57/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 34378.7431 - val_loss: 45172.9639\n",
      "Epoch 58/1000\n",
      "1137/1137 [==============================] - 0s 372us/step - loss: 34734.8009 - val_loss: 45552.6721\n",
      "Epoch 59/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 34185.4762 - val_loss: 45275.1348\n",
      "Epoch 60/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 33798.8025 - val_loss: 44526.7808\n",
      "Epoch 61/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 34147.7657 - val_loss: 44405.8403\n",
      "Epoch 62/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 34351.0683 - val_loss: 44311.5979\n",
      "Epoch 63/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 34329.4634 - val_loss: 44346.8153\n",
      "Epoch 64/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 33756.2433 - val_loss: 44356.0061\n",
      "Epoch 65/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 33951.8175 - val_loss: 44595.2192\n",
      "Epoch 66/1000\n",
      "1137/1137 [==============================] - 0s 373us/step - loss: 33807.0536 - val_loss: 44393.4732\n",
      "Epoch 67/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 33757.5423 - val_loss: 44335.3248\n",
      "Epoch 68/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 34139.5444 - val_loss: 44548.3976\n",
      "Epoch 69/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 33427.9802 - val_loss: 46392.0119\n",
      "Epoch 70/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: 34376.9619 - val_loss: 44404.9198\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 396us/step - loss: 33790.3570 - val_loss: 45263.0427\n",
      "Epoch 72/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 33860.0462 - val_loss: 45018.8892\n",
      "Epoch 73/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 33900.2538 - val_loss: 44654.8305\n",
      "Epoch 74/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 33678.9904 - val_loss: 44670.6389\n",
      "Epoch 75/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 33420.9467 - val_loss: 45969.0506\n",
      "Epoch 76/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 33219.2458 - val_loss: 44811.9341\n",
      "Epoch 77/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 33507.6825 - val_loss: 44604.0287\n",
      "Epoch 78/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 33470.8913 - val_loss: 44788.2709\n",
      "Epoch 79/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 33585.6086 - val_loss: 45245.1186\n",
      "Epoch 80/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 33403.9771 - val_loss: 48018.0197\n",
      "Epoch 81/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 33749.7646 - val_loss: 44627.2299\n",
      "Epoch 82/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 33257.5111 - val_loss: 44549.8903\n",
      "Epoch 83/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 33045.3742 - val_loss: 44874.4701\n",
      "Epoch 84/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 33025.0957 - val_loss: 44668.0800\n",
      "Epoch 85/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 33246.0685 - val_loss: 44640.3248\n",
      "Epoch 86/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 33043.8148 - val_loss: 45291.4345\n",
      "Epoch 87/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 32913.7686 - val_loss: 44622.4103\n",
      "Epoch 88/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 33137.5088 - val_loss: 44880.4606\n",
      "Epoch 89/1000\n",
      "1137/1137 [==============================] - 0s 407us/step - loss: 33244.1143 - val_loss: 44883.0820\n",
      "Epoch 90/1000\n",
      "1137/1137 [==============================] - 0s 418us/step - loss: 33039.3733 - val_loss: 44577.9207\n",
      "Epoch 91/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 32506.3231 - val_loss: 44568.8583\n",
      "Epoch 92/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 32451.0420 - val_loss: 45110.6287\n",
      "Epoch 93/1000\n",
      "1137/1137 [==============================] - 0s 407us/step - loss: 33005.2521 - val_loss: 46009.6491\n",
      "Epoch 94/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 32806.1665 - val_loss: 44863.7569\n",
      "Epoch 95/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 32867.7006 - val_loss: 44948.0746\n",
      "Epoch 96/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 32647.2965 - val_loss: 45415.3126\n",
      "Epoch 97/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 32455.5872 - val_loss: 44545.6808\n",
      "Epoch 98/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 32913.5428 - val_loss: 44542.4140\n",
      "Epoch 99/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 32170.6720 - val_loss: 45004.4699\n",
      "Epoch 100/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 32859.6009 - val_loss: 44889.7613\n",
      "Epoch 101/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 32743.4225 - val_loss: 44662.4704\n",
      "Epoch 102/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 32632.3369 - val_loss: 44594.4616\n",
      "Epoch 103/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 32566.3765 - val_loss: 45294.3618\n",
      "Epoch 104/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 32865.9098 - val_loss: 47624.4574\n",
      "Epoch 105/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 32902.8169 - val_loss: 44708.3106\n",
      "Epoch 106/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 32469.3735 - val_loss: 44988.7982\n",
      "Epoch 107/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 32304.7733 - val_loss: 44821.7396\n",
      "Epoch 108/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 32755.4577 - val_loss: 44850.5229\n",
      "Epoch 109/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 32129.9723 - val_loss: 44852.1962\n",
      "Epoch 110/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 32521.2095 - val_loss: 45950.4709\n",
      "Epoch 111/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 32565.8703 - val_loss: 44963.8371\n",
      "Epoch 112/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 32428.3796 - val_loss: 44739.9939\n",
      "Epoch 113/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 32399.7872 - val_loss: 44740.2365\n",
      "Epoch 114/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 32209.1666 - val_loss: 44765.1883\n",
      "Epoch 115/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 32288.7470 - val_loss: 45141.8831\n",
      "Epoch 116/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 32632.0908 - val_loss: 45760.8311\n",
      "Epoch 117/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 31816.6412 - val_loss: 44902.5863\n",
      "Epoch 118/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 32476.6306 - val_loss: 44775.4325\n",
      "Epoch 119/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 32125.7731 - val_loss: 45113.8535\n",
      "Epoch 120/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 32323.3368 - val_loss: 44652.6367\n",
      "Epoch 121/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 31961.0768 - val_loss: 44667.5536\n",
      "Epoch 122/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 32084.0672 - val_loss: 45479.8446\n",
      "Epoch 123/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 32209.9365 - val_loss: 44655.2817\n",
      "Epoch 124/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 31808.3199 - val_loss: 44705.4975\n",
      "Epoch 125/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: 31618.2249 - val_loss: 44821.8450\n",
      "Epoch 126/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 31579.5024 - val_loss: 45666.0822\n",
      "Epoch 127/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 31865.3123 - val_loss: 44845.0959\n",
      "Epoch 128/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 31784.8938 - val_loss: 44640.7704\n",
      "Epoch 129/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 32164.5810 - val_loss: 45039.7216\n",
      "Epoch 130/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 32068.2919 - val_loss: 47171.8005\n",
      "Epoch 131/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 31568.4442 - val_loss: 44960.5004\n",
      "Epoch 132/1000\n",
      "1137/1137 [==============================] - 0s 373us/step - loss: 31811.5056 - val_loss: 46065.6317\n",
      "Epoch 133/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 31640.9872 - val_loss: 44800.5178\n",
      "Epoch 134/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 31520.5515 - val_loss: 45493.2476\n",
      "Epoch 135/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 31679.3045 - val_loss: 45040.7819\n",
      "Epoch 136/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 31561.9619 - val_loss: 45912.4972\n",
      "Epoch 137/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 31108.8752 - val_loss: 45050.9850\n",
      "Epoch 138/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 31579.5436 - val_loss: 44797.6129\n",
      "Epoch 139/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: 31664.6568 - val_loss: 44611.9487\n",
      "Epoch 140/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 31464.9893 - val_loss: 45300.8768\n",
      "Epoch 141/1000\n",
      "1137/1137 [==============================] - 0s 370us/step - loss: 31464.5566 - val_loss: 44751.2474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 31587.2780 - val_loss: 44565.9979\n",
      "Epoch 143/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 31263.2957 - val_loss: 46929.8490\n",
      "Epoch 144/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 31484.2581 - val_loss: 44765.8177\n",
      "Epoch 145/1000\n",
      "1137/1137 [==============================] - 0s 418us/step - loss: 31585.1174 - val_loss: 44504.4685\n",
      "Epoch 146/1000\n",
      "1137/1137 [==============================] - 0s 414us/step - loss: 31771.8285 - val_loss: 44347.7850\n",
      "Epoch 147/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 31578.8417 - val_loss: 46495.8388\n",
      "Epoch 148/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 31664.0471 - val_loss: 44443.4144\n",
      "Epoch 149/1000\n",
      "1137/1137 [==============================] - 0s 414us/step - loss: 31492.0591 - val_loss: 44701.7054\n",
      "Epoch 150/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 31600.4972 - val_loss: 44392.4742\n",
      "Epoch 151/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 31059.3791 - val_loss: 44312.7697\n",
      "Epoch 152/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 31256.2357 - val_loss: 45400.0007\n",
      "Epoch 153/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 30985.1127 - val_loss: 44567.6898\n",
      "Epoch 154/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 31068.8914 - val_loss: 44957.6613\n",
      "Epoch 155/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 31441.6995 - val_loss: 44228.6242\n",
      "Epoch 156/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 31519.1367 - val_loss: 47745.8804\n",
      "Epoch 157/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 31589.5452 - val_loss: 44155.2893\n",
      "Epoch 158/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 31190.1546 - val_loss: 45013.1727\n",
      "Epoch 159/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 31120.5743 - val_loss: 45244.3843\n",
      "Epoch 160/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 30901.4783 - val_loss: 44416.4734\n",
      "Epoch 161/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 31102.3552 - val_loss: 45079.3305\n",
      "Epoch 162/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 30625.8136 - val_loss: 45166.4769\n",
      "Epoch 163/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 30909.5999 - val_loss: 44183.8741\n",
      "Epoch 164/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 30823.9321 - val_loss: 45454.1112\n",
      "Epoch 165/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 30409.7287 - val_loss: 45869.5268\n",
      "Epoch 166/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 29058.722 - 0s 384us/step - loss: 30582.1967 - val_loss: 44568.8825\n",
      "Epoch 167/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 30836.5033 - val_loss: 44169.0618\n",
      "Epoch 168/1000\n",
      "1137/1137 [==============================] - 1s 458us/step - loss: 31340.4992 - val_loss: 43873.7338\n",
      "Epoch 169/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 31149.3654 - val_loss: 45672.6522\n",
      "Epoch 170/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: 31209.8780 - val_loss: 43865.4431\n",
      "Epoch 171/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 30704.3060 - val_loss: 44060.1306\n",
      "Epoch 172/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 31122.9793 - val_loss: 44122.2634\n",
      "Epoch 173/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 30692.0426 - val_loss: 43788.0285\n",
      "Epoch 174/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 30793.7202 - val_loss: 47390.4731\n",
      "Epoch 175/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 30795.8833 - val_loss: 43751.8488\n",
      "Epoch 176/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 30306.3212 - val_loss: 43864.4483\n",
      "Epoch 177/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 30538.1872 - val_loss: 43625.4656\n",
      "Epoch 178/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 30054.7960 - val_loss: 43678.9113\n",
      "Epoch 179/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 30645.4988 - val_loss: 43869.6751\n",
      "Epoch 180/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 30634.3420 - val_loss: 46254.0821\n",
      "Epoch 181/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 30501.0259 - val_loss: 43547.1753\n",
      "Epoch 182/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 30311.5738 - val_loss: 43420.5073\n",
      "Epoch 183/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 30172.5444 - val_loss: 44491.8629\n",
      "Epoch 184/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 30233.3157 - val_loss: 44903.6080\n",
      "Epoch 185/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 30491.4290 - val_loss: 43416.7885\n",
      "Epoch 186/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 30354.7449 - val_loss: 43972.5448\n",
      "Epoch 187/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 30127.1392 - val_loss: 45036.5217\n",
      "Epoch 188/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 30734.3761 - val_loss: 43900.4324\n",
      "Epoch 189/1000\n",
      "1137/1137 [==============================] - 0s 410us/step - loss: 30527.3653 - val_loss: 43639.3050\n",
      "Epoch 190/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 30165.5228 - val_loss: 45102.8694\n",
      "Epoch 191/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 30508.6188 - val_loss: 43714.5219\n",
      "Epoch 192/1000\n",
      "1137/1137 [==============================] - 0s 367us/step - loss: 29612.1712 - val_loss: 43249.7342\n",
      "Epoch 193/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 29502.5117 - val_loss: 43655.8912\n",
      "Epoch 194/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 30016.7645 - val_loss: 43909.1837\n",
      "Epoch 195/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 29851.6219 - val_loss: 44219.9778\n",
      "Epoch 196/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 29539.0764 - val_loss: 44337.8240\n",
      "Epoch 197/1000\n",
      "1137/1137 [==============================] - 0s 370us/step - loss: 29641.8990 - val_loss: 43165.0752\n",
      "Epoch 198/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 29859.1356 - val_loss: 43528.5973\n",
      "Epoch 199/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 29402.2267 - val_loss: 43069.7490\n",
      "Epoch 200/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 29650.6850 - val_loss: 43080.5950\n",
      "Epoch 201/1000\n",
      "1137/1137 [==============================] - 0s 367us/step - loss: 29245.6530 - val_loss: 43420.8182\n",
      "Epoch 202/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 29638.2682 - val_loss: 43923.1213\n",
      "Epoch 203/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 29818.6215 - val_loss: 43184.5811\n",
      "Epoch 204/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 29476.2670 - val_loss: 43399.7652\n",
      "Epoch 205/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 29534.9379 - val_loss: 42704.4250\n",
      "Epoch 206/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 29245.8252 - val_loss: 43040.6858\n",
      "Epoch 207/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 29310.4951 - val_loss: 43569.4752\n",
      "Epoch 208/1000\n",
      "1137/1137 [==============================] - 0s 371us/step - loss: 29543.6513 - val_loss: 44021.1564\n",
      "Epoch 209/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 29253.0927 - val_loss: 43011.5658\n",
      "Epoch 210/1000\n",
      "1137/1137 [==============================] - 0s 363us/step - loss: 29670.5399 - val_loss: 46039.6085\n",
      "Epoch 211/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 29488.9103 - val_loss: 43090.7090\n",
      "Epoch 212/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 392us/step - loss: 29414.6122 - val_loss: 42619.1901\n",
      "Epoch 213/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 29204.2067 - val_loss: 44085.4689\n",
      "Epoch 214/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 29401.5736 - val_loss: 43074.1943\n",
      "Epoch 215/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 28888.6565 - val_loss: 43193.0877\n",
      "Epoch 216/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 29196.9240 - val_loss: 42354.3463\n",
      "Epoch 217/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 28738.5959 - val_loss: 42330.6920\n",
      "Epoch 218/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 28912.8009 - val_loss: 42625.8706\n",
      "Epoch 219/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 28981.2302 - val_loss: 42642.7962\n",
      "Epoch 220/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 28786.1939 - val_loss: 42358.8765\n",
      "Epoch 221/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 29265.6176 - val_loss: 43491.1752\n",
      "Epoch 222/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 29109.2838 - val_loss: 42585.0343\n",
      "Epoch 223/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 28727.7944 - val_loss: 45151.3440\n",
      "Epoch 224/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 28268.5296 - val_loss: 42125.5231\n",
      "Epoch 225/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 28941.2004 - val_loss: 41955.6778\n",
      "Epoch 226/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 28466.8384 - val_loss: 44035.9254\n",
      "Epoch 227/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 28586.6815 - val_loss: 41997.1523\n",
      "Epoch 228/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 28885.1543 - val_loss: 41756.8573\n",
      "Epoch 229/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 28150.9421 - val_loss: 42519.3502\n",
      "Epoch 230/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 28341.4891 - val_loss: 42831.4997\n",
      "Epoch 231/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 28245.6209 - val_loss: 41669.9909\n",
      "Epoch 232/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 28071.5354 - val_loss: 42674.3028\n",
      "Epoch 233/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 28235.5557 - val_loss: 41730.9069\n",
      "Epoch 234/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 28318.8621 - val_loss: 44293.8295\n",
      "Epoch 235/1000\n",
      "1137/1137 [==============================] - 0s 414us/step - loss: 28643.3661 - val_loss: 42597.7933\n",
      "Epoch 236/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 28682.4090 - val_loss: 43485.1252\n",
      "Epoch 237/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 27941.6183 - val_loss: 41640.7253\n",
      "Epoch 238/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 28150.9371 - val_loss: 41865.8846\n",
      "Epoch 239/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 27739.1444 - val_loss: 41851.4031\n",
      "Epoch 240/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 27502.1128 - val_loss: 41605.2832\n",
      "Epoch 241/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 27834.8695 - val_loss: 41282.0640\n",
      "Epoch 242/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 27732.7635 - val_loss: 41820.2635\n",
      "Epoch 243/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 27830.8512 - val_loss: 41411.6058\n",
      "Epoch 244/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 27673.6619 - val_loss: 42788.3550\n",
      "Epoch 245/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 28350.9143 - val_loss: 43024.3819\n",
      "Epoch 246/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 27563.0925 - val_loss: 41620.6189\n",
      "Epoch 247/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 27569.8988 - val_loss: 41798.4569\n",
      "Epoch 248/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 27213.3513 - val_loss: 42104.7785\n",
      "Epoch 249/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 27159.1220 - val_loss: 43400.8523\n",
      "Epoch 250/1000\n",
      "1137/1137 [==============================] - 0s 413us/step - loss: 28254.8015 - val_loss: 41092.2414\n",
      "Epoch 251/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 27735.9098 - val_loss: 43705.9304\n",
      "Epoch 252/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 27669.0461 - val_loss: 41502.8723\n",
      "Epoch 253/1000\n",
      "1137/1137 [==============================] - 0s 374us/step - loss: 27279.3986 - val_loss: 41930.6942\n",
      "Epoch 254/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 27445.2013 - val_loss: 41975.9164\n",
      "Epoch 255/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 27389.3252 - val_loss: 40641.3515\n",
      "Epoch 256/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 27042.0472 - val_loss: 41914.9014\n",
      "Epoch 257/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 27112.4039 - val_loss: 40495.4502\n",
      "Epoch 258/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 27522.2298 - val_loss: 40712.3763\n",
      "Epoch 259/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 26867.7869 - val_loss: 40368.2906\n",
      "Epoch 260/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 27047.1333 - val_loss: 40312.9514\n",
      "Epoch 261/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 26583.0359 - val_loss: 40820.2035\n",
      "Epoch 262/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 27322.3105 - val_loss: 40443.9579\n",
      "Epoch 263/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 27103.4809 - val_loss: 40359.6617\n",
      "Epoch 264/1000\n",
      "1137/1137 [==============================] - 0s 374us/step - loss: 27037.9482 - val_loss: 40822.2130\n",
      "Epoch 265/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 27229.9311 - val_loss: 40830.6030\n",
      "Epoch 266/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 26633.0637 - val_loss: 40542.6694\n",
      "Epoch 267/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 26816.9220 - val_loss: 40571.8226\n",
      "Epoch 268/1000\n",
      "1137/1137 [==============================] - 0s 366us/step - loss: 27187.2642 - val_loss: 41737.4520\n",
      "Epoch 269/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 27341.9207 - val_loss: 41011.5287\n",
      "Epoch 270/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 26758.0788 - val_loss: 40291.0016\n",
      "Epoch 271/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 26581.4786 - val_loss: 41255.0013\n",
      "Epoch 272/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 26835.6663 - val_loss: 40010.7121\n",
      "Epoch 273/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 26776.2000 - val_loss: 40138.2277\n",
      "Epoch 274/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 26659.489 - 0s 384us/step - loss: 26823.5755 - val_loss: 40129.0027\n",
      "Epoch 275/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 26803.3731 - val_loss: 40649.9114\n",
      "Epoch 276/1000\n",
      "1137/1137 [==============================] - 0s 409us/step - loss: 27071.2252 - val_loss: 40241.8513\n",
      "Epoch 277/1000\n",
      "1137/1137 [==============================] - 0s 366us/step - loss: 26435.2108 - val_loss: 39676.0053\n",
      "Epoch 278/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 26573.7678 - val_loss: 39743.6810\n",
      "Epoch 279/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 26054.3584 - val_loss: 40139.5454\n",
      "Epoch 280/1000\n",
      "1137/1137 [==============================] - 0s 370us/step - loss: 25851.0648 - val_loss: 39396.4538\n",
      "Epoch 281/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 26164.0209 - val_loss: 40466.9030\n",
      "Epoch 282/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 386us/step - loss: 25943.1013 - val_loss: 39750.6494\n",
      "Epoch 283/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 26769.2385 - val_loss: 40256.3223\n",
      "Epoch 284/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 25939.1243 - val_loss: 41541.0995\n",
      "Epoch 285/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 26194.1363 - val_loss: 39380.5466\n",
      "Epoch 286/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 26191.5594 - val_loss: 39213.9003\n",
      "Epoch 287/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 25718.2337 - val_loss: 39299.8385\n",
      "Epoch 288/1000\n",
      "1137/1137 [==============================] - 0s 407us/step - loss: 26130.5027 - val_loss: 40602.9010\n",
      "Epoch 289/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 25811.6815 - val_loss: 41638.7768\n",
      "Epoch 290/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 25620.0041 - val_loss: 40931.3713\n",
      "Epoch 291/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 26177.0812 - val_loss: 41696.6138\n",
      "Epoch 292/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 26173.4822 - val_loss: 38959.3927\n",
      "Epoch 293/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 26294.8656 - val_loss: 41445.7521\n",
      "Epoch 294/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 25884.9165 - val_loss: 38760.5379\n",
      "Epoch 295/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 25920.1350 - val_loss: 38940.8770\n",
      "Epoch 296/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 26400.4877 - val_loss: 39441.3713\n",
      "Epoch 297/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 25641.6902 - val_loss: 40885.4298\n",
      "Epoch 298/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 25623.7415 - val_loss: 38786.6203\n",
      "Epoch 299/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 25592.8678 - val_loss: 39204.2267\n",
      "Epoch 300/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 25887.1791 - val_loss: 38648.3829\n",
      "Epoch 301/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 25708.7309 - val_loss: 39428.9713\n",
      "Epoch 302/1000\n",
      "1137/1137 [==============================] - 1s 445us/step - loss: 26107.9934 - val_loss: 39282.5225\n",
      "Epoch 303/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 25353.6838 - val_loss: 40468.1975\n",
      "Epoch 304/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 25259.2683 - val_loss: 38959.8112\n",
      "Epoch 305/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 25960.3445 - val_loss: 38869.0659\n",
      "Epoch 306/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 25949.9104 - val_loss: 39294.0541\n",
      "Epoch 307/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 25197.7399 - val_loss: 38429.4772\n",
      "Epoch 308/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 25265.1291 - val_loss: 38699.1537\n",
      "Epoch 309/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 25136.8556 - val_loss: 38091.9891\n",
      "Epoch 310/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 25302.4841 - val_loss: 38237.1162\n",
      "Epoch 311/1000\n",
      "1137/1137 [==============================] - 0s 367us/step - loss: 25002.7832 - val_loss: 39043.2797\n",
      "Epoch 312/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 25663.4159 - val_loss: 38654.8100\n",
      "Epoch 313/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 25289.2861 - val_loss: 38408.4600\n",
      "Epoch 314/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 25427.6710 - val_loss: 39833.7416\n",
      "Epoch 315/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 24816.7343 - val_loss: 43293.2918\n",
      "Epoch 316/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 25234.7410 - val_loss: 40330.4824\n",
      "Epoch 317/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 24955.8022 - val_loss: 38089.3293\n",
      "Epoch 318/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 25337.8062 - val_loss: 38704.3109\n",
      "Epoch 319/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 24818.4978 - val_loss: 38893.4560\n",
      "Epoch 320/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 24616.3468 - val_loss: 38488.4720\n",
      "Epoch 321/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 25146.0847 - val_loss: 39170.9987\n",
      "Epoch 322/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 24899.0194 - val_loss: 39160.2687\n",
      "Epoch 323/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 24638.3129 - val_loss: 39028.7538\n",
      "Epoch 324/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 24606.8926 - val_loss: 38852.2012\n",
      "Epoch 325/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 24755.0536 - val_loss: 41180.2439\n",
      "Epoch 326/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 24867.0553 - val_loss: 37858.3827\n",
      "Epoch 327/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 24565.7722 - val_loss: 38330.5399\n",
      "Epoch 328/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 24703.2596 - val_loss: 40432.9801\n",
      "Epoch 329/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: 24549.9784 - val_loss: 38931.1269\n",
      "Epoch 330/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 25066.9047 - val_loss: 37624.7807\n",
      "Epoch 331/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 25304.7892 - val_loss: 37753.2777\n",
      "Epoch 332/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 24621.4024 - val_loss: 38013.3288\n",
      "Epoch 333/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 23920.7006 - val_loss: 39861.3371\n",
      "Epoch 334/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 24816.6425 - val_loss: 37477.4519\n",
      "Epoch 335/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 24757.0904 - val_loss: 37889.6932\n",
      "Epoch 336/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 25180.4950 - val_loss: 37856.2810\n",
      "Epoch 337/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 24724.502 - 0s 385us/step - loss: 24610.5515 - val_loss: 37882.1199\n",
      "Epoch 338/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 24734.7465 - val_loss: 39699.9567\n",
      "Epoch 339/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 24560.5191 - val_loss: 37594.4049\n",
      "Epoch 340/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 24957.1109 - val_loss: 37764.5822\n",
      "Epoch 341/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 24677.6313 - val_loss: 37779.9739\n",
      "Epoch 342/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 25487.6423 - val_loss: 38334.2180\n",
      "Epoch 343/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 24111.3361 - val_loss: 38081.8173\n",
      "Epoch 344/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 24759.5689 - val_loss: 37967.2047\n",
      "Epoch 345/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 24463.1790 - val_loss: 38621.2414\n",
      "Epoch 346/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 24906.5718 - val_loss: 39678.8721\n",
      "Epoch 347/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: 24726.5373 - val_loss: 38071.3517\n",
      "Epoch 348/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 24256.0036 - val_loss: 37352.5299\n",
      "Epoch 349/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 23960.5814 - val_loss: 38308.5966\n",
      "Epoch 350/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 24115.5369 - val_loss: 38599.8052\n",
      "Epoch 351/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 24546.6520 - val_loss: 37284.4545\n",
      "Epoch 352/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 389us/step - loss: 24527.3336 - val_loss: 37191.0991\n",
      "Epoch 353/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 23973.1391 - val_loss: 37092.4536\n",
      "Epoch 354/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 24137.9632 - val_loss: 39914.8420\n",
      "Epoch 355/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 24494.2941 - val_loss: 37019.7343\n",
      "Epoch 356/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 23992.0546 - val_loss: 37358.1502\n",
      "Epoch 357/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 24460.4134 - val_loss: 37606.8207\n",
      "Epoch 358/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 23730.2777 - val_loss: 38661.8834\n",
      "Epoch 359/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 24071.4730 - val_loss: 37584.6116\n",
      "Epoch 360/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 24337.4367 - val_loss: 37181.6171\n",
      "Epoch 361/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 23817.7731 - val_loss: 39535.9294\n",
      "Epoch 362/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 24859.7045 - val_loss: 37564.1166\n",
      "Epoch 363/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 23694.7168 - val_loss: 37432.0632\n",
      "Epoch 364/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 23627.6504 - val_loss: 37963.1294\n",
      "Epoch 365/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 24450.8055 - val_loss: 37270.2704\n",
      "Epoch 366/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 24691.891 - 0s 392us/step - loss: 24693.5674 - val_loss: 37161.3706\n",
      "Epoch 367/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 24607.2218 - val_loss: 37402.0057\n",
      "Epoch 368/1000\n",
      "1137/1137 [==============================] - 0s 404us/step - loss: 23780.0962 - val_loss: 37286.7025\n",
      "Epoch 369/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 23563.1723 - val_loss: 38565.0305\n",
      "Epoch 370/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 24013.0490 - val_loss: 37074.2272\n",
      "Epoch 371/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 23872.2501 - val_loss: 37606.7810\n",
      "Epoch 372/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 23502.0253 - val_loss: 38742.5768\n",
      "Epoch 373/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 23970.5201 - val_loss: 37823.9652\n",
      "Epoch 374/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 24907.4449 - val_loss: 38114.8996\n",
      "Epoch 375/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 24261.0088 - val_loss: 36995.4518\n",
      "Epoch 376/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 24174.8805 - val_loss: 36934.7936\n",
      "Epoch 377/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 23901.2443 - val_loss: 37114.7207\n",
      "Epoch 378/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 24105.0146 - val_loss: 37498.2592\n",
      "Epoch 379/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 24484.8235 - val_loss: 36930.2297\n",
      "Epoch 380/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 24228.8854 - val_loss: 36967.6661\n",
      "Epoch 381/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 23319.1015 - val_loss: 38232.8610\n",
      "Epoch 382/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 24233.4350 - val_loss: 36909.1683\n",
      "Epoch 383/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 23376.7879 - val_loss: 37450.2647\n",
      "Epoch 384/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 24331.0908 - val_loss: 36631.2102\n",
      "Epoch 385/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 24027.5527 - val_loss: 36566.7152\n",
      "Epoch 386/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 23311.4446 - val_loss: 37863.0738\n",
      "Epoch 387/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 23622.8253 - val_loss: 37011.1856\n",
      "Epoch 388/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 23786.1245 - val_loss: 38944.5848\n",
      "Epoch 389/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 23072.5910 - val_loss: 40519.1971\n",
      "Epoch 390/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 23310.3264 - val_loss: 39442.2792\n",
      "Epoch 391/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 24579.7861 - val_loss: 44322.0469\n",
      "Epoch 392/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 23705.2484 - val_loss: 36790.2787\n",
      "Epoch 393/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 24112.0704 - val_loss: 36846.3118\n",
      "Epoch 394/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 23762.7920 - val_loss: 38507.9979\n",
      "Epoch 395/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 24709.2400 - val_loss: 37210.0085\n",
      "Epoch 396/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 23254.9404 - val_loss: 38857.5532\n",
      "Epoch 397/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 23493.1486 - val_loss: 37807.4223\n",
      "Epoch 398/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 23404.0227 - val_loss: 36907.2155\n",
      "Epoch 399/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 23298.2386 - val_loss: 36798.5647\n",
      "Epoch 400/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 23471.6875 - val_loss: 36981.9573\n",
      "Epoch 401/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 23984.6732 - val_loss: 39535.5230\n",
      "Epoch 402/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 23637.4592 - val_loss: 36875.7768\n",
      "Epoch 403/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 24056.2427 - val_loss: 37651.9219\n",
      "Epoch 404/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 23627.8558 - val_loss: 37081.7394\n",
      "Epoch 405/1000\n",
      "1137/1137 [==============================] - 0s 366us/step - loss: 23955.8470 - val_loss: 36974.9499\n",
      "Epoch 406/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 23514.0096 - val_loss: 40177.0246\n",
      "Epoch 407/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 24574.2205 - val_loss: 36610.3145\n",
      "Epoch 408/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 23622.7423 - val_loss: 41958.0649\n",
      "Epoch 409/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 23186.9414 - val_loss: 38413.9423\n",
      "Epoch 410/1000\n",
      "1137/1137 [==============================] - 0s 372us/step - loss: 22975.7238 - val_loss: 40671.6180\n",
      "Epoch 411/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 23233.4866 - val_loss: 39274.3509\n",
      "Epoch 412/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 23481.5705 - val_loss: 37537.6899\n",
      "Epoch 413/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 23793.8254 - val_loss: 37899.0381\n",
      "Epoch 414/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 23511.4471 - val_loss: 37094.5680\n",
      "Epoch 415/1000\n",
      "1137/1137 [==============================] - 0s 363us/step - loss: 23198.5653 - val_loss: 40209.5597\n",
      "Epoch 416/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 23770.0238 - val_loss: 36753.5136\n",
      "Epoch 417/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 22936.6352 - val_loss: 36984.6582\n",
      "Epoch 418/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22963.6057 - val_loss: 37202.3067\n",
      "Epoch 419/1000\n",
      "1137/1137 [==============================] - 0s 366us/step - loss: 23339.6264 - val_loss: 37448.0261\n",
      "Epoch 420/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 23115.5770 - val_loss: 37316.1495\n",
      "Epoch 421/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 23240.4957 - val_loss: 38233.1662\n",
      "Epoch 422/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 382us/step - loss: 23408.9167 - val_loss: 36621.8245\n",
      "Epoch 423/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 22622.5128 - val_loss: 36447.3642\n",
      "Epoch 424/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 22766.2092 - val_loss: 37021.9112\n",
      "Epoch 425/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 22837.7097 - val_loss: 36704.5488\n",
      "Epoch 426/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 22858.1976 - val_loss: 37020.0682\n",
      "Epoch 427/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 23163.6008 - val_loss: 37199.1441\n",
      "Epoch 428/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 24022.4356 - val_loss: 36717.4870\n",
      "Epoch 429/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 22994.1533 - val_loss: 37660.7368\n",
      "Epoch 430/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 23302.7705 - val_loss: 38449.0709\n",
      "Epoch 431/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 22980.1346 - val_loss: 37321.8617\n",
      "Epoch 432/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 23118.9468 - val_loss: 36733.0645\n",
      "Epoch 433/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 22752.9913 - val_loss: 37282.6853\n",
      "Epoch 434/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 22929.9257 - val_loss: 36512.9910\n",
      "Epoch 435/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 23869.3548 - val_loss: 37154.8460\n",
      "Epoch 436/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 22796.4145 - val_loss: 36466.8944\n",
      "Epoch 437/1000\n",
      "1137/1137 [==============================] - 0s 428us/step - loss: 22540.0706 - val_loss: 36515.9426\n",
      "Epoch 438/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 22716.9140 - val_loss: 37205.0541\n",
      "Epoch 439/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 22824.9662 - val_loss: 36460.2607\n",
      "Epoch 440/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 22659.9992 - val_loss: 36950.2576\n",
      "Epoch 441/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 23263.7986 - val_loss: 36419.5804\n",
      "Epoch 442/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 22551.2268 - val_loss: 36581.1761\n",
      "Epoch 443/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 22782.6579 - val_loss: 38039.1203\n",
      "Epoch 444/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 22597.5986 - val_loss: 37677.2319\n",
      "Epoch 445/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 22772.0239 - val_loss: 38214.2139\n",
      "Epoch 446/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 23964.4774 - val_loss: 36153.1057\n",
      "Epoch 447/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 22878.6608 - val_loss: 35944.6753\n",
      "Epoch 448/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 22868.1501 - val_loss: 36879.5075\n",
      "Epoch 449/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22968.6271 - val_loss: 36120.0817\n",
      "Epoch 450/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 22481.7068 - val_loss: 37731.2908\n",
      "Epoch 451/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 22776.6782 - val_loss: 37885.6137\n",
      "Epoch 452/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 22995.9069 - val_loss: 36239.3564\n",
      "Epoch 453/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 23441.8197 - val_loss: 36271.2197\n",
      "Epoch 454/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 23263.2996 - val_loss: 36860.6300\n",
      "Epoch 455/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: 23360.5861 - val_loss: 38510.3298\n",
      "Epoch 456/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 23539.5482 - val_loss: 36054.7537\n",
      "Epoch 457/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 22354.0929 - val_loss: 37341.5169\n",
      "Epoch 458/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 22713.7745 - val_loss: 39083.2034\n",
      "Epoch 459/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 22679.0328 - val_loss: 36130.0039\n",
      "Epoch 460/1000\n",
      "1137/1137 [==============================] - 0s 374us/step - loss: 22401.2527 - val_loss: 36817.0952\n",
      "Epoch 461/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 22327.2703 - val_loss: 36170.4582\n",
      "Epoch 462/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 23085.7815 - val_loss: 39030.0773\n",
      "Epoch 463/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 22629.6971 - val_loss: 36883.3134\n",
      "Epoch 464/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 22981.5745 - val_loss: 35985.5449\n",
      "Epoch 465/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 22080.8692 - val_loss: 36121.4152\n",
      "Epoch 466/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 22145.3386 - val_loss: 36332.9670\n",
      "Epoch 467/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 22925.9280 - val_loss: 37004.3662\n",
      "Epoch 468/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22211.9918 - val_loss: 36371.6560\n",
      "Epoch 469/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 22793.3016 - val_loss: 36354.7688\n",
      "Epoch 470/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 22211.1273 - val_loss: 37022.8426\n",
      "Epoch 471/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 21989.0418 - val_loss: 35942.2892\n",
      "Epoch 472/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 23101.9710 - val_loss: 35971.0562\n",
      "Epoch 473/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 22771.6662 - val_loss: 36110.3330\n",
      "Epoch 474/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 21930.5924 - val_loss: 36006.0396\n",
      "Epoch 475/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 22715.7101 - val_loss: 35863.9569\n",
      "Epoch 476/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 22475.9956 - val_loss: 37742.7316\n",
      "Epoch 477/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 22501.1341 - val_loss: 36270.2903\n",
      "Epoch 478/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 22468.3773 - val_loss: 38142.1367\n",
      "Epoch 479/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 22328.9554 - val_loss: 38336.2227\n",
      "Epoch 480/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 23060.5471 - val_loss: 36480.7581\n",
      "Epoch 481/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22991.3147 - val_loss: 36854.4295\n",
      "Epoch 482/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 22080.1008 - val_loss: 36729.7314\n",
      "Epoch 483/1000\n",
      "1137/1137 [==============================] - 0s 373us/step - loss: 22132.9626 - val_loss: 36272.2508\n",
      "Epoch 484/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 22207.0736 - val_loss: 37219.9651\n",
      "Epoch 485/1000\n",
      "1137/1137 [==============================] - 0s 370us/step - loss: 23014.4890 - val_loss: 36966.6313\n",
      "Epoch 486/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 23226.3548 - val_loss: 36865.0962\n",
      "Epoch 487/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 22694.2136 - val_loss: 37309.9631\n",
      "Epoch 488/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 22796.6509 - val_loss: 36617.4088\n",
      "Epoch 489/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 22163.4491 - val_loss: 36489.6626\n",
      "Epoch 490/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 22092.6475 - val_loss: 37449.5439\n",
      "Epoch 491/1000\n",
      "1137/1137 [==============================] - 0s 362us/step - loss: 22407.7404 - val_loss: 37064.2517\n",
      "Epoch 492/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 22256.5573 - val_loss: 35969.1719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 22275.3479 - val_loss: 35782.0484\n",
      "Epoch 494/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 23429.2310 - val_loss: 36127.5573\n",
      "Epoch 495/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 22338.6323 - val_loss: 36008.0574\n",
      "Epoch 496/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 22190.2608 - val_loss: 36629.0042\n",
      "Epoch 497/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 22118.8544 - val_loss: 36419.7293\n",
      "Epoch 498/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22067.3414 - val_loss: 36765.4970\n",
      "Epoch 499/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 21960.2058 - val_loss: 36204.0969\n",
      "Epoch 500/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 21885.8608 - val_loss: 36806.0926\n",
      "Epoch 501/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 21873.187 - 0s 387us/step - loss: 21802.5696 - val_loss: 35709.5394\n",
      "Epoch 502/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 22204.7928 - val_loss: 36956.9367\n",
      "Epoch 503/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 21836.5565 - val_loss: 36966.7726\n",
      "Epoch 504/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 22445.8069 - val_loss: 38428.5928\n",
      "Epoch 505/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 22031.7269 - val_loss: 36870.8702\n",
      "Epoch 506/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 22322.2915 - val_loss: 36891.2892\n",
      "Epoch 507/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 21453.4331 - val_loss: 36284.2803\n",
      "Epoch 508/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 21941.637 - 0s 396us/step - loss: 21773.0474 - val_loss: 36013.5462\n",
      "Epoch 509/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 22322.4266 - val_loss: 36199.3767\n",
      "Epoch 510/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 23227.5947 - val_loss: 36824.7296\n",
      "Epoch 511/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 21797.3398 - val_loss: 37309.1509\n",
      "Epoch 512/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 21558.5387 - val_loss: 36583.0175\n",
      "Epoch 513/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 22255.7958 - val_loss: 37734.3415\n",
      "Epoch 514/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 20900.045 - 0s 394us/step - loss: 22329.8561 - val_loss: 36340.9827\n",
      "Epoch 515/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 21846.9422 - val_loss: 36185.6819\n",
      "Epoch 516/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 22133.0749 - val_loss: 36335.4437\n",
      "Epoch 517/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 22055.3941 - val_loss: 35780.5371\n",
      "Epoch 518/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 21639.7431 - val_loss: 35930.7885\n",
      "Epoch 519/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22490.0829 - val_loss: 36001.7201\n",
      "Epoch 520/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 22454.3714 - val_loss: 37167.3278\n",
      "Epoch 521/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 21694.7705 - val_loss: 36687.6946\n",
      "Epoch 522/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 21410.2275 - val_loss: 35565.1248\n",
      "Epoch 523/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 21574.0453 - val_loss: 35686.5955\n",
      "Epoch 524/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 21891.1052 - val_loss: 35841.8986\n",
      "Epoch 525/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 22154.1110 - val_loss: 35244.1387\n",
      "Epoch 526/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 21831.5980 - val_loss: 35955.1254\n",
      "Epoch 527/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 22301.4369 - val_loss: 37404.6433\n",
      "Epoch 528/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 21171.7195 - val_loss: 36174.5198\n",
      "Epoch 529/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 22815.9351 - val_loss: 35690.3000\n",
      "Epoch 530/1000\n",
      "1137/1137 [==============================] - 0s 369us/step - loss: 21990.8668 - val_loss: 35659.5579\n",
      "Epoch 531/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21512.4459 - val_loss: 35633.0200\n",
      "Epoch 532/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 22022.7663 - val_loss: 35786.8234\n",
      "Epoch 533/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21891.2711 - val_loss: 37679.6301\n",
      "Epoch 534/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 21666.6945 - val_loss: 35700.9906\n",
      "Epoch 535/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 22009.5693 - val_loss: 37181.1637\n",
      "Epoch 536/1000\n",
      "1137/1137 [==============================] - 0s 373us/step - loss: 22164.7158 - val_loss: 36169.0922\n",
      "Epoch 537/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 21960.2901 - val_loss: 35485.8273\n",
      "Epoch 538/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 21966.7681 - val_loss: 35663.3552\n",
      "Epoch 539/1000\n",
      "1137/1137 [==============================] - 0s 372us/step - loss: 21380.4030 - val_loss: 36081.5625\n",
      "Epoch 540/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21493.1179 - val_loss: 36286.1677\n",
      "Epoch 541/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22082.1756 - val_loss: 35333.9813\n",
      "Epoch 542/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 21742.8001 - val_loss: 36064.5998\n",
      "Epoch 543/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 22193.6794 - val_loss: 42239.2004\n",
      "Epoch 544/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 22127.7750 - val_loss: 35532.4796\n",
      "Epoch 545/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 22277.3945 - val_loss: 35363.0217\n",
      "Epoch 546/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 21699.0492 - val_loss: 35841.1956\n",
      "Epoch 547/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22016.3170 - val_loss: 38566.7803\n",
      "Epoch 548/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 21271.6364 - val_loss: 35973.3406\n",
      "Epoch 549/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 20985.0956 - val_loss: 35094.0612\n",
      "Epoch 550/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 21146.1135 - val_loss: 35728.6214\n",
      "Epoch 551/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 21674.7143 - val_loss: 35795.8505\n",
      "Epoch 552/1000\n",
      "1137/1137 [==============================] - 0s 369us/step - loss: 21108.0611 - val_loss: 35835.1868\n",
      "Epoch 553/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 21511.0103 - val_loss: 38319.5705\n",
      "Epoch 554/1000\n",
      "1137/1137 [==============================] - 0s 373us/step - loss: 21390.8333 - val_loss: 35833.9456\n",
      "Epoch 555/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 22330.5600 - val_loss: 35914.7021\n",
      "Epoch 556/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 21441.4714 - val_loss: 35516.1556\n",
      "Epoch 557/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 21078.4501 - val_loss: 35764.2017\n",
      "Epoch 558/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 21224.9819 - val_loss: 36198.2931\n",
      "Epoch 559/1000\n",
      "1137/1137 [==============================] - 0s 374us/step - loss: 21596.3998 - val_loss: 36331.6855\n",
      "Epoch 560/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 21355.2219 - val_loss: 35734.0741\n",
      "Epoch 561/1000\n",
      "1137/1137 [==============================] - 0s 371us/step - loss: 21374.2378 - val_loss: 35888.9164\n",
      "Epoch 562/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 22218.6099 - val_loss: 34988.5422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 563/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 21841.8209 - val_loss: 35419.1862\n",
      "Epoch 564/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 21104.0430 - val_loss: 35308.3521\n",
      "Epoch 565/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 20632.2535 - val_loss: 36054.8751\n",
      "Epoch 566/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 21548.4070 - val_loss: 36958.0257\n",
      "Epoch 567/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 21445.8276 - val_loss: 38148.0205\n",
      "Epoch 568/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 21075.3468 - val_loss: 35942.8794\n",
      "Epoch 569/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 20961.9112 - val_loss: 36753.8079\n",
      "Epoch 570/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 22243.2507 - val_loss: 35288.4164\n",
      "Epoch 571/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 21663.2829 - val_loss: 36550.6387\n",
      "Epoch 572/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21854.2203 - val_loss: 35200.3069\n",
      "Epoch 573/1000\n",
      "1137/1137 [==============================] - 0s 404us/step - loss: 21141.2280 - val_loss: 35175.8392\n",
      "Epoch 574/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 21666.5041 - val_loss: 37835.9964\n",
      "Epoch 575/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 21449.1979 - val_loss: 35159.1212\n",
      "Epoch 576/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 20982.7543 - val_loss: 35659.9944\n",
      "Epoch 577/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 21165.3033 - val_loss: 35941.4588\n",
      "Epoch 578/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 21100.0514 - val_loss: 36563.6746\n",
      "Epoch 579/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 21611.6227 - val_loss: 36276.3762\n",
      "Epoch 580/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 21238.9306 - val_loss: 38909.5513\n",
      "Epoch 581/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 21448.1538 - val_loss: 36124.3896\n",
      "Epoch 582/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 21426.3361 - val_loss: 34907.2488\n",
      "Epoch 583/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 21327.7178 - val_loss: 36221.9030\n",
      "Epoch 584/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21333.7224 - val_loss: 36903.1295\n",
      "Epoch 585/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 20891.7953 - val_loss: 35609.9016\n",
      "Epoch 586/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 21240.4344 - val_loss: 36066.2347\n",
      "Epoch 587/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 21169.7405 - val_loss: 35242.6425\n",
      "Epoch 588/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 21169.3523 - val_loss: 36427.0356\n",
      "Epoch 589/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 20816.7644 - val_loss: 36399.0032\n",
      "Epoch 590/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 20985.4157 - val_loss: 34968.3466\n",
      "Epoch 591/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 20470.4609 - val_loss: 35206.1801\n",
      "Epoch 592/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 20475.4890 - val_loss: 35363.6620\n",
      "Epoch 593/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 21061.7275 - val_loss: 35519.5927\n",
      "Epoch 594/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 21386.1006 - val_loss: 36030.6072\n",
      "Epoch 595/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 20540.7501 - val_loss: 35551.0431\n",
      "Epoch 596/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 20372.2842 - val_loss: 35595.2105\n",
      "Epoch 597/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 20363.9182 - val_loss: 36712.5042\n",
      "Epoch 598/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 21259.7635 - val_loss: 35109.0729\n",
      "Epoch 599/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 20850.5993 - val_loss: 35237.5790\n",
      "Epoch 600/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 21066.6038 - val_loss: 35574.0624\n",
      "Epoch 601/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 20785.7865 - val_loss: 37584.3507\n",
      "Epoch 602/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 21002.0744 - val_loss: 35351.5949\n",
      "Epoch 603/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 20651.0667 - val_loss: 35368.9240\n",
      "Epoch 604/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 21330.8555 - val_loss: 34810.6266\n",
      "Epoch 605/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 20869.0711 - val_loss: 34631.8095\n",
      "Epoch 606/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 20743.7347 - val_loss: 36165.9640\n",
      "Epoch 607/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 20749.5524 - val_loss: 34746.2018\n",
      "Epoch 608/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 21034.9189 - val_loss: 38914.8027\n",
      "Epoch 609/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 21400.5475 - val_loss: 35679.0320\n",
      "Epoch 610/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 20442.2679 - val_loss: 35344.9070\n",
      "Epoch 611/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 20131.7934 - val_loss: 36283.0169\n",
      "Epoch 612/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 20698.6475 - val_loss: 37291.9853\n",
      "Epoch 613/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 20958.9453 - val_loss: 34976.6978\n",
      "Epoch 614/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 20844.2422 - val_loss: 37089.4512\n",
      "Epoch 615/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 21015.9680 - val_loss: 39206.4547\n",
      "Epoch 616/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 21177.4527 - val_loss: 35303.8613\n",
      "Epoch 617/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 20604.1718 - val_loss: 35039.6735\n",
      "Epoch 618/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 20806.9497 - val_loss: 36736.5262\n",
      "Epoch 619/1000\n",
      "1137/1137 [==============================] - 0s 363us/step - loss: 21463.4899 - val_loss: 35567.0237\n",
      "Epoch 620/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21333.7238 - val_loss: 37776.1670\n",
      "Epoch 621/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 20811.7278 - val_loss: 34852.8213\n",
      "Epoch 622/1000\n",
      "1137/1137 [==============================] - 0s 369us/step - loss: 21496.0914 - val_loss: 36147.2590\n",
      "Epoch 623/1000\n",
      "1137/1137 [==============================] - 0s 370us/step - loss: 20509.6702 - val_loss: 37064.3181\n",
      "Epoch 624/1000\n",
      "1137/1137 [==============================] - 0s 373us/step - loss: 20788.1569 - val_loss: 35199.8221\n",
      "Epoch 625/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 20632.8048 - val_loss: 36156.6675\n",
      "Epoch 626/1000\n",
      "1137/1137 [==============================] - 0s 366us/step - loss: 20755.4981 - val_loss: 36729.3562\n",
      "Epoch 627/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 20280.3686 - val_loss: 35359.5328\n",
      "Epoch 628/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 20322.1927 - val_loss: 34978.8159\n",
      "Epoch 629/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 20271.9951 - val_loss: 35619.0382\n",
      "Epoch 630/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 20398.6640 - val_loss: 35289.7026\n",
      "Epoch 631/1000\n",
      "1137/1137 [==============================] - 0s 371us/step - loss: 21119.7019 - val_loss: 35959.2384\n",
      "Epoch 632/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 20782.8480 - val_loss: 35064.7545\n",
      "Epoch 633/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 388us/step - loss: 21206.1978 - val_loss: 40318.2825\n",
      "Epoch 634/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 21215.7114 - val_loss: 34970.0892\n",
      "Epoch 635/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21004.3146 - val_loss: 34456.1101\n",
      "Epoch 636/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 20654.3006 - val_loss: 36490.1092\n",
      "Epoch 637/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 20360.0682 - val_loss: 34916.6583\n",
      "Epoch 638/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 21245.5753 - val_loss: 35370.0234\n",
      "Epoch 639/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 20489.0892 - val_loss: 35593.3022\n",
      "Epoch 640/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 20525.6404 - val_loss: 34932.5984\n",
      "Epoch 641/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 20194.5244 - val_loss: 35140.5225\n",
      "Epoch 642/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21211.8457 - val_loss: 35455.6356\n",
      "Epoch 643/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 20396.5852 - val_loss: 35487.0490\n",
      "Epoch 644/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 20187.3958 - val_loss: 34575.0758\n",
      "Epoch 645/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 22331.9807 - val_loss: 34656.0043\n",
      "Epoch 646/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 20501.1095 - val_loss: 34894.5636\n",
      "Epoch 647/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 20118.7760 - val_loss: 34421.7374\n",
      "Epoch 648/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 20311.4587 - val_loss: 35958.0158\n",
      "Epoch 649/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 21279.9819 - val_loss: 36207.2411\n",
      "Epoch 650/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 20468.7109 - val_loss: 34603.4181\n",
      "Epoch 651/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 20523.3741 - val_loss: 35954.5894\n",
      "Epoch 652/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 20408.3913 - val_loss: 35161.2461\n",
      "Epoch 653/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 20388.9883 - val_loss: 34787.6237\n",
      "Epoch 654/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 20322.6605 - val_loss: 35277.3169\n",
      "Epoch 655/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 20527.7745 - val_loss: 34834.5332\n",
      "Epoch 656/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 20667.3051 - val_loss: 34509.5003\n",
      "Epoch 657/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 20553.7268 - val_loss: 34994.9210\n",
      "Epoch 658/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 20882.1728 - val_loss: 34849.8231\n",
      "Epoch 659/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 20999.154 - 0s 393us/step - loss: 20837.3967 - val_loss: 36012.5711\n",
      "Epoch 660/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 20378.4294 - val_loss: 34562.5532\n",
      "Epoch 661/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 20138.1712 - val_loss: 34777.9696\n",
      "Epoch 662/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 21116.1711 - val_loss: 35076.2139\n",
      "Epoch 663/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 20214.0830 - val_loss: 34609.9232\n",
      "Epoch 664/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 20527.1803 - val_loss: 39455.1150\n",
      "Epoch 665/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 20455.9817 - val_loss: 35692.4865\n",
      "Epoch 666/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 19883.3603 - val_loss: 37866.3476\n",
      "Epoch 667/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 20558.4288 - val_loss: 34509.3855\n",
      "Epoch 668/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 20375.4838 - val_loss: 36154.9906\n",
      "Epoch 669/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 20709.5037 - val_loss: 35283.3407\n",
      "Epoch 670/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 19888.2797 - val_loss: 35036.0741\n",
      "Epoch 671/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 20321.8312 - val_loss: 34616.9996\n",
      "Epoch 672/1000\n",
      "1137/1137 [==============================] - 0s 404us/step - loss: 20323.9188 - val_loss: 35696.5863\n",
      "Epoch 673/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 20348.7279 - val_loss: 34513.9260\n",
      "Epoch 674/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 20229.5903 - val_loss: 36004.4755\n",
      "Epoch 675/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 20481.9755 - val_loss: 34251.5971\n",
      "Epoch 676/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 20142.4992 - val_loss: 35360.0989\n",
      "Epoch 677/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 19992.5460 - val_loss: 35178.6473\n",
      "Epoch 678/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 19887.3452 - val_loss: 37003.1035\n",
      "Epoch 679/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 19713.9766 - val_loss: 36534.8128\n",
      "Epoch 680/1000\n",
      "1137/1137 [==============================] - 0s 355us/step - loss: 20252.6128 - val_loss: 35596.5897\n",
      "Epoch 681/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 21425.2182 - val_loss: 34816.1256\n",
      "Epoch 682/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 20809.3424 - val_loss: 35304.6060\n",
      "Epoch 683/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 20828.1100 - val_loss: 34698.3193\n",
      "Epoch 684/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 20366.1149 - val_loss: 34381.5236\n",
      "Epoch 685/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 20289.3364 - val_loss: 35254.6779\n",
      "Epoch 686/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 19610.9485 - val_loss: 37922.5996\n",
      "Epoch 687/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 19708.2670 - val_loss: 35081.2247\n",
      "Epoch 688/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 20205.5325 - val_loss: 35123.1861\n",
      "Epoch 689/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 19541.1697 - val_loss: 35091.3551\n",
      "Epoch 690/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 20019.3853 - val_loss: 34903.9285\n",
      "Epoch 691/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 20132.4881 - val_loss: 35229.9674\n",
      "Epoch 692/1000\n",
      "1137/1137 [==============================] - 0s 369us/step - loss: 19905.8953 - val_loss: 36946.5264\n",
      "Epoch 693/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 19586.4639 - val_loss: 35536.7164\n",
      "Epoch 694/1000\n",
      "1137/1137 [==============================] - 0s 378us/step - loss: 19704.1032 - val_loss: 34530.5899\n",
      "Epoch 695/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 19385.0552 - val_loss: 35102.2607\n",
      "Epoch 696/1000\n",
      "1137/1137 [==============================] - 0s 376us/step - loss: 19926.7684 - val_loss: 34806.6977\n",
      "Epoch 697/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 21147.0112 - val_loss: 34899.4727\n",
      "Epoch 698/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 20588.8434 - val_loss: 35236.8469\n",
      "Epoch 699/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 19943.7743 - val_loss: 38233.9231\n",
      "Epoch 700/1000\n",
      "1137/1137 [==============================] - 0s 379us/step - loss: 19980.1186 - val_loss: 34509.9571\n",
      "Epoch 701/1000\n",
      "1137/1137 [==============================] - 0s 374us/step - loss: 19714.5523 - val_loss: 35385.1223\n",
      "Epoch 702/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 19593.9011 - val_loss: 35291.0005\n",
      "Epoch 703/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 376us/step - loss: 20445.2766 - val_loss: 36276.1146\n",
      "Epoch 704/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19899.1280 - val_loss: 36239.7119\n",
      "Epoch 705/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 19625.3050 - val_loss: 35073.7486\n",
      "Epoch 706/1000\n",
      "1137/1137 [==============================] - 0s 404us/step - loss: 19792.5993 - val_loss: 34311.8824\n",
      "Epoch 707/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 20499.9828 - val_loss: 35195.1200\n",
      "Epoch 708/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 19770.2217 - val_loss: 34887.5851\n",
      "Epoch 709/1000\n",
      "1137/1137 [==============================] - 0s 410us/step - loss: 19498.0482 - val_loss: 36447.5213\n",
      "Epoch 710/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 19839.9201 - val_loss: 34462.0463\n",
      "Epoch 711/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 20025.8126 - val_loss: 36834.9891\n",
      "Epoch 712/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 19475.5395 - val_loss: 35229.3009\n",
      "Epoch 713/1000\n",
      "1137/1137 [==============================] - 0s 407us/step - loss: 20083.7307 - val_loss: 34136.7917\n",
      "Epoch 714/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19776.3440 - val_loss: 34362.1753\n",
      "Epoch 715/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 20372.6787 - val_loss: 36625.2952\n",
      "Epoch 716/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 19731.4522 - val_loss: 34856.8188\n",
      "Epoch 717/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 20065.2442 - val_loss: 35409.4601\n",
      "Epoch 718/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19497.5072 - val_loss: 34895.2597\n",
      "Epoch 719/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 20050.5233 - val_loss: 35720.2773\n",
      "Epoch 720/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 19981.4637 - val_loss: 34733.2267\n",
      "Epoch 721/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: 20162.0276 - val_loss: 34391.5175\n",
      "Epoch 722/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 19698.9246 - val_loss: 34050.3248\n",
      "Epoch 723/1000\n",
      "1137/1137 [==============================] - 2s 2ms/step - loss: 19793.8108 - val_loss: 34785.1335\n",
      "Epoch 724/1000\n",
      "1137/1137 [==============================] - 0s 200us/step - loss: 19885.9894 - val_loss: 34094.4676\n",
      "Epoch 725/1000\n",
      "1137/1137 [==============================] - 0s 222us/step - loss: 19960.8770 - val_loss: 34444.7995\n",
      "Epoch 726/1000\n",
      "1137/1137 [==============================] - 0s 201us/step - loss: 19749.3534 - val_loss: 33901.0486\n",
      "Epoch 727/1000\n",
      "1137/1137 [==============================] - 0s 196us/step - loss: 20409.4459 - val_loss: 35519.3232\n",
      "Epoch 728/1000\n",
      "1137/1137 [==============================] - 0s 192us/step - loss: 20004.5214 - val_loss: 34185.4840\n",
      "Epoch 729/1000\n",
      "1137/1137 [==============================] - 0s 226us/step - loss: 19560.0992 - val_loss: 34509.6902\n",
      "Epoch 730/1000\n",
      "1137/1137 [==============================] - 0s 423us/step - loss: 19731.6006 - val_loss: 34113.1238\n",
      "Epoch 731/1000\n",
      "1137/1137 [==============================] - 0s 412us/step - loss: 19605.5175 - val_loss: 34039.7179\n",
      "Epoch 732/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 19054.4820 - val_loss: 34812.5080\n",
      "Epoch 733/1000\n",
      "1137/1137 [==============================] - 0s 418us/step - loss: 19832.4828 - val_loss: 38957.9249\n",
      "Epoch 734/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 19951.9247 - val_loss: 38178.1854\n",
      "Epoch 735/1000\n",
      "1137/1137 [==============================] - 0s 410us/step - loss: 19784.3062 - val_loss: 34232.1733\n",
      "Epoch 736/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 19687.5257 - val_loss: 34424.7096\n",
      "Epoch 737/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 19738.7294 - val_loss: 34945.8344\n",
      "Epoch 738/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 20080.6255 - val_loss: 34965.3377\n",
      "Epoch 739/1000\n",
      "1137/1137 [==============================] - 0s 415us/step - loss: 19806.5408 - val_loss: 33840.5022\n",
      "Epoch 740/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19655.3856 - val_loss: 35848.1684\n",
      "Epoch 741/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 20410.6935 - val_loss: 34489.9100\n",
      "Epoch 742/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 19881.2758 - val_loss: 35273.6221\n",
      "Epoch 743/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 19654.3540 - val_loss: 35004.8121\n",
      "Epoch 744/1000\n",
      "1137/1137 [==============================] - 0s 409us/step - loss: 19506.8303 - val_loss: 34330.5298\n",
      "Epoch 745/1000\n",
      "1137/1137 [==============================] - 0s 416us/step - loss: 19758.4218 - val_loss: 34351.8079\n",
      "Epoch 746/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 20234.6238 - val_loss: 37151.1057\n",
      "Epoch 747/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 19808.4537 - val_loss: 34266.7851\n",
      "Epoch 748/1000\n",
      "1137/1137 [==============================] - 0s 417us/step - loss: 20328.0077 - val_loss: 36034.0095\n",
      "Epoch 749/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 20316.5403 - val_loss: 34396.4993\n",
      "Epoch 750/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 19898.3197 - val_loss: 34909.4556\n",
      "Epoch 751/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19657.1121 - val_loss: 34340.4567\n",
      "Epoch 752/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 19542.0369 - val_loss: 34600.0218\n",
      "Epoch 753/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 19285.8025 - val_loss: 35808.3639\n",
      "Epoch 754/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 19827.9202 - val_loss: 36808.1175\n",
      "Epoch 755/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19865.5305 - val_loss: 35052.0180\n",
      "Epoch 756/1000\n",
      "1137/1137 [==============================] - 0s 407us/step - loss: 19151.8215 - val_loss: 35257.4164\n",
      "Epoch 757/1000\n",
      "1137/1137 [==============================] - 0s 404us/step - loss: 19338.5410 - val_loss: 35757.6155\n",
      "Epoch 758/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19415.4439 - val_loss: 34614.4483\n",
      "Epoch 759/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19390.9762 - val_loss: 35047.4612\n",
      "Epoch 760/1000\n",
      "1137/1137 [==============================] - 0s 412us/step - loss: 19072.8724 - val_loss: 36825.2883\n",
      "Epoch 761/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19214.1322 - val_loss: 34518.4128\n",
      "Epoch 762/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 19378.4377 - val_loss: 33755.1693\n",
      "Epoch 763/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 19547.1869 - val_loss: 34144.3399\n",
      "Epoch 764/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 19982.7858 - val_loss: 35556.5887\n",
      "Epoch 765/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 19450.3807 - val_loss: 34579.9595\n",
      "Epoch 766/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19766.0920 - val_loss: 34473.3831\n",
      "Epoch 767/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19247.4689 - val_loss: 34082.0110\n",
      "Epoch 768/1000\n",
      "1137/1137 [==============================] - 0s 383us/step - loss: 19008.1891 - val_loss: 34255.8051\n",
      "Epoch 769/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19843.5743 - val_loss: 35866.4071\n",
      "Epoch 770/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 19996.5016 - val_loss: 35153.5872\n",
      "Epoch 771/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 19805.0818 - val_loss: 36616.1688\n",
      "Epoch 772/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19676.3478 - val_loss: 36952.8576\n",
      "Epoch 773/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19405.1615 - val_loss: 38706.0546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 774/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 19434.3093 - val_loss: 34153.9487\n",
      "Epoch 775/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 19442.7455 - val_loss: 36841.6105\n",
      "Epoch 776/1000\n",
      "1137/1137 [==============================] - 0s 418us/step - loss: 19748.4560 - val_loss: 34069.5754\n",
      "Epoch 777/1000\n",
      "1137/1137 [==============================] - 0s 404us/step - loss: 20212.5509 - val_loss: 34018.8825\n",
      "Epoch 778/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 19225.7255 - val_loss: 34025.5344\n",
      "Epoch 779/1000\n",
      "1137/1137 [==============================] - 0s 407us/step - loss: 19764.2585 - val_loss: 35916.5572\n",
      "Epoch 780/1000\n",
      "1137/1137 [==============================] - 0s 412us/step - loss: 19120.0183 - val_loss: 34225.7250\n",
      "Epoch 781/1000\n",
      "1137/1137 [==============================] - 0s 409us/step - loss: 19024.4664 - val_loss: 35962.3263\n",
      "Epoch 782/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 19571.3455 - val_loss: 34120.4127\n",
      "Epoch 783/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 19132.9649 - val_loss: 33744.1104\n",
      "Epoch 784/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 18672.2641 - val_loss: 34003.4819\n",
      "Epoch 785/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 19104.8338 - val_loss: 34348.4023\n",
      "Epoch 786/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19396.5846 - val_loss: 33838.7796\n",
      "Epoch 787/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 19204.4929 - val_loss: 33784.3986\n",
      "Epoch 788/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 18811.3181 - val_loss: 34323.9431\n",
      "Epoch 789/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 19442.5937 - val_loss: 34056.2680\n",
      "Epoch 790/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 19180.2023 - val_loss: 34545.9426\n",
      "Epoch 791/1000\n",
      "1137/1137 [==============================] - 0s 410us/step - loss: 19780.9304 - val_loss: 33810.7465\n",
      "Epoch 792/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 19223.9463 - val_loss: 34244.8214\n",
      "Epoch 793/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 19508.5918 - val_loss: 36670.3945\n",
      "Epoch 794/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 19771.7167 - val_loss: 34638.6505\n",
      "Epoch 795/1000\n",
      "1137/1137 [==============================] - 0s 409us/step - loss: 19584.9024 - val_loss: 34783.3456\n",
      "Epoch 796/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 18832.8585 - val_loss: 35227.6592\n",
      "Epoch 797/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 19085.9742 - val_loss: 34849.7565\n",
      "Epoch 798/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 19105.7911 - val_loss: 36071.7428\n",
      "Epoch 799/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19102.7044 - val_loss: 34862.9528\n",
      "Epoch 800/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 19663.1349 - val_loss: 35656.7821\n",
      "Epoch 801/1000\n",
      "1137/1137 [==============================] - 0s 385us/step - loss: 19033.0219 - val_loss: 36023.2870\n",
      "Epoch 802/1000\n",
      "1137/1137 [==============================] - 0s 387us/step - loss: 19327.9410 - val_loss: 34661.9610\n",
      "Epoch 803/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 19636.9250 - val_loss: 35854.9023\n",
      "Epoch 804/1000\n",
      "1137/1137 [==============================] - 0s 410us/step - loss: 18949.8638 - val_loss: 34477.9036\n",
      "Epoch 805/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 19031.9941 - val_loss: 35705.2114\n",
      "Epoch 806/1000\n",
      "1137/1137 [==============================] - 0s 404us/step - loss: 19099.6470 - val_loss: 34648.5563\n",
      "Epoch 807/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 18612.7166 - val_loss: 34762.6259\n",
      "Epoch 808/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 18949.7952 - val_loss: 34272.4263\n",
      "Epoch 809/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 18613.7522 - val_loss: 35659.2769\n",
      "Epoch 810/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 19222.3189 - val_loss: 34102.2254\n",
      "Epoch 811/1000\n",
      "1137/1137 [==============================] - 0s 409us/step - loss: 20110.0682 - val_loss: 33635.6943\n",
      "Epoch 812/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 18927.2861 - val_loss: 33827.4489\n",
      "Epoch 813/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 18864.7727 - val_loss: 35951.0241\n",
      "Epoch 814/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 19893.7502 - val_loss: 33768.8358\n",
      "Epoch 815/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 19462.1986 - val_loss: 36026.4515\n",
      "Epoch 816/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 19320.7592 - val_loss: 34195.0952\n",
      "Epoch 817/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 18526.3617 - val_loss: 34068.0320\n",
      "Epoch 818/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 18857.0975 - val_loss: 33443.5648\n",
      "Epoch 819/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 18897.2092 - val_loss: 35138.0169\n",
      "Epoch 820/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 19312.6303 - val_loss: 35139.4277\n",
      "Epoch 821/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 18872.3054 - val_loss: 34960.1819\n",
      "Epoch 822/1000\n",
      "1137/1137 [==============================] - 0s 393us/step - loss: 19221.2383 - val_loss: 33427.5887\n",
      "Epoch 823/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 19227.3484 - val_loss: 34585.5165\n",
      "Epoch 824/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 18846.8076 - val_loss: 33813.4589\n",
      "Epoch 825/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 18631.7466 - val_loss: 35462.1652\n",
      "Epoch 826/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19109.2176 - val_loss: 33738.7245\n",
      "Epoch 827/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 19088.0529 - val_loss: 35505.9974\n",
      "Epoch 828/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 18686.2247 - val_loss: 35062.5201\n",
      "Epoch 829/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19049.5187 - val_loss: 34687.7109\n",
      "Epoch 830/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 19046.6711 - val_loss: 33632.2545\n",
      "Epoch 831/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 19515.8693 - val_loss: 36848.5788\n",
      "Epoch 832/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 18740.3595 - val_loss: 34615.3568\n",
      "Epoch 833/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 19210.8176 - val_loss: 34000.8039\n",
      "Epoch 834/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 18991.2676 - val_loss: 34890.4771\n",
      "Epoch 835/1000\n",
      "1137/1137 [==============================] - 0s 402us/step - loss: 18498.8891 - val_loss: 33887.1120\n",
      "Epoch 836/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 19129.1401 - val_loss: 35837.1387\n",
      "Epoch 837/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 19700.8269 - val_loss: 34380.6742\n",
      "Epoch 838/1000\n",
      "1137/1137 [==============================] - 1s 490us/step - loss: 18984.7096 - val_loss: 37196.8742\n",
      "Epoch 839/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 18747.2490 - val_loss: 34668.5198\n",
      "Epoch 840/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 19144.4522 - val_loss: 33952.8818\n",
      "Epoch 841/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 19277.4161 - val_loss: 34706.5829\n",
      "Epoch 842/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 19203.1574 - val_loss: 34601.4249\n",
      "Epoch 843/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 19520.1302 - val_loss: 36040.9771\n",
      "Epoch 844/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 408us/step - loss: 19582.4894 - val_loss: 33589.0149\n",
      "Epoch 845/1000\n",
      "1137/1137 [==============================] - 0s 412us/step - loss: 18756.7666 - val_loss: 34898.7004\n",
      "Epoch 846/1000\n",
      "1137/1137 [==============================] - 0s 413us/step - loss: 18604.2846 - val_loss: 34291.8056\n",
      "Epoch 847/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 18576.1038 - val_loss: 35779.5808\n",
      "Epoch 848/1000\n",
      "1137/1137 [==============================] - 0s 413us/step - loss: 18658.2121 - val_loss: 33690.9022\n",
      "Epoch 849/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 18478.7346 - val_loss: 33699.0345\n",
      "Epoch 850/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 18682.0481 - val_loss: 33942.8891\n",
      "Epoch 851/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 19924.6473 - val_loss: 34968.9922\n",
      "Epoch 852/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 18862.4239 - val_loss: 34261.2220\n",
      "Epoch 853/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 18439.9447 - val_loss: 35390.6812\n",
      "Epoch 854/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: 18472.2711 - val_loss: 35487.0088\n",
      "Epoch 855/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 18900.5249 - val_loss: 35207.2221\n",
      "Epoch 856/1000\n",
      "1137/1137 [==============================] - 0s 410us/step - loss: 18790.9818 - val_loss: 35373.3996\n",
      "Epoch 857/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 18715.4087 - val_loss: 35092.5205\n",
      "Epoch 858/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 19195.9302 - val_loss: 33662.2200\n",
      "Epoch 859/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 18769.1258 - val_loss: 34097.6172\n",
      "Epoch 860/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 19270.6625 - val_loss: 33732.9777\n",
      "Epoch 861/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 18641.6995 - val_loss: 33985.2889\n",
      "Epoch 862/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 18239.4267 - val_loss: 34435.9811\n",
      "Epoch 863/1000\n",
      "1137/1137 [==============================] - 0s 417us/step - loss: 19171.1218 - val_loss: 33700.1432\n",
      "Epoch 864/1000\n",
      "1137/1137 [==============================] - 0s 430us/step - loss: 18922.3607 - val_loss: 36412.9045\n",
      "Epoch 865/1000\n",
      "1137/1137 [==============================] - 0s 414us/step - loss: 19295.4351 - val_loss: 33905.9550\n",
      "Epoch 866/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 18620.4497 - val_loss: 33882.2780\n",
      "Epoch 867/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 18476.5850 - val_loss: 33722.1622\n",
      "Epoch 868/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 18611.8147 - val_loss: 33343.2817\n",
      "Epoch 869/1000\n",
      "1137/1137 [==============================] - 0s 415us/step - loss: 19379.6872 - val_loss: 34230.6246\n",
      "Epoch 870/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 19129.7022 - val_loss: 35105.8694\n",
      "Epoch 871/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 18798.5218 - val_loss: 35022.4638\n",
      "Epoch 872/1000\n",
      "1137/1137 [==============================] - 0s 409us/step - loss: 19178.7621 - val_loss: 33541.9183\n",
      "Epoch 873/1000\n",
      "1137/1137 [==============================] - 0s 410us/step - loss: 17983.0560 - val_loss: 34716.3206\n",
      "Epoch 874/1000\n",
      "1137/1137 [==============================] - 0s 407us/step - loss: 18228.2112 - val_loss: 35999.0316\n",
      "Epoch 875/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 18640.1316 - val_loss: 34771.9692\n",
      "Epoch 876/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 19041.6489 - val_loss: 33583.3134\n",
      "Epoch 877/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 18562.0584 - val_loss: 34422.8360\n",
      "Epoch 878/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 17993.0787 - val_loss: 34795.3841\n",
      "Epoch 879/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 18818.1677 - val_loss: 33655.7078\n",
      "Epoch 880/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 18268.5941 - val_loss: 34202.9012\n",
      "Epoch 881/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 18734.6636 - val_loss: 39244.4794\n",
      "Epoch 882/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 18528.1282 - val_loss: 34074.1880\n",
      "Epoch 883/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 18373.9069 - val_loss: 33575.8834\n",
      "Epoch 884/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 18641.9741 - val_loss: 34044.4308\n",
      "Epoch 885/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 19865.2321 - val_loss: 33334.2122\n",
      "Epoch 886/1000\n",
      "1137/1137 [==============================] - 0s 418us/step - loss: 18275.1297 - val_loss: 33486.3513\n",
      "Epoch 887/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 18630.1577 - val_loss: 36384.9140\n",
      "Epoch 888/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 18454.0794 - val_loss: 33593.1333\n",
      "Epoch 889/1000\n",
      "1137/1137 [==============================] - 0s 392us/step - loss: 18652.5320 - val_loss: 33774.3858\n",
      "Epoch 890/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 18300.0178 - val_loss: 34055.2181\n",
      "Epoch 891/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 18512.3676 - val_loss: 33581.6407\n",
      "Epoch 892/1000\n",
      "1137/1137 [==============================] - 0s 365us/step - loss: 18689.6212 - val_loss: 33875.7218\n",
      "Epoch 893/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 18615.8028 - val_loss: 33808.0415\n",
      "Epoch 894/1000\n",
      "1137/1137 [==============================] - 1s 499us/step - loss: 18760.4500 - val_loss: 35034.3268\n",
      "Epoch 895/1000\n",
      "1137/1137 [==============================] - 0s 434us/step - loss: 19178.4708 - val_loss: 34576.6163\n",
      "Epoch 896/1000\n",
      "1137/1137 [==============================] - 0s 437us/step - loss: 18269.4158 - val_loss: 35369.3573\n",
      "Epoch 897/1000\n",
      "1137/1137 [==============================] - 0s 408us/step - loss: 18219.9145 - val_loss: 33413.6322\n",
      "Epoch 898/1000\n",
      "1137/1137 [==============================] - 1s 447us/step - loss: 19080.6345 - val_loss: 34591.0907\n",
      "Epoch 899/1000\n",
      "1137/1137 [==============================] - 0s 417us/step - loss: 18251.8918 - val_loss: 42778.0168\n",
      "Epoch 900/1000\n",
      "1137/1137 [==============================] - 1s 441us/step - loss: 18487.6604 - val_loss: 34716.9226\n",
      "Epoch 901/1000\n",
      "1137/1137 [==============================] - 1s 492us/step - loss: 18378.3940 - val_loss: 33970.2177\n",
      "Epoch 902/1000\n",
      "1137/1137 [==============================] - 0s 439us/step - loss: 18363.4915 - val_loss: 34062.7331\n",
      "Epoch 903/1000\n",
      "1137/1137 [==============================] - 0s 416us/step - loss: 18529.8778 - val_loss: 33500.6960\n",
      "Epoch 904/1000\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 17969.5727 - val_loss: 33547.3138\n",
      "Epoch 905/1000\n",
      "1137/1137 [==============================] - 1s 446us/step - loss: 18423.5174 - val_loss: 34623.2732\n",
      "Epoch 906/1000\n",
      "1137/1137 [==============================] - 0s 413us/step - loss: 18078.0606 - val_loss: 34622.8839\n",
      "Epoch 907/1000\n",
      "1137/1137 [==============================] - 1s 452us/step - loss: 19389.4323 - val_loss: 33606.8043\n",
      "Epoch 908/1000\n",
      "1137/1137 [==============================] - 1s 452us/step - loss: 18916.5690 - val_loss: 33574.8274\n",
      "Epoch 909/1000\n",
      "1137/1137 [==============================] - 0s 419us/step - loss: 18377.8991 - val_loss: 33634.0282\n",
      "Epoch 910/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 18663.4333 - val_loss: 35667.7965\n",
      "Epoch 911/1000\n",
      "1137/1137 [==============================] - 1s 461us/step - loss: 18094.0802 - val_loss: 34137.4894\n",
      "Epoch 912/1000\n",
      "1137/1137 [==============================] - 1s 453us/step - loss: 18668.5898 - val_loss: 34636.3126\n",
      "Epoch 913/1000\n",
      "1137/1137 [==============================] - 1s 625us/step - loss: 18515.9329 - val_loss: 34470.6239\n",
      "Epoch 914/1000\n",
      "1137/1137 [==============================] - 1s 606us/step - loss: 19111.3236 - val_loss: 34597.8345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915/1000\n",
      "1137/1137 [==============================] - 1s 449us/step - loss: 18343.6406 - val_loss: 35196.3684\n",
      "Epoch 916/1000\n",
      "1137/1137 [==============================] - 1s 454us/step - loss: 18620.4401 - val_loss: 33343.9355\n",
      "Epoch 917/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 17733.8438 - val_loss: 33308.2695\n",
      "Epoch 918/1000\n",
      "1137/1137 [==============================] - 1s 518us/step - loss: 18309.9470 - val_loss: 35306.1055\n",
      "Epoch 919/1000\n",
      "1137/1137 [==============================] - 1s 502us/step - loss: 17981.2208 - val_loss: 33979.3170\n",
      "Epoch 920/1000\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 18029.0871 - val_loss: 34340.2437\n",
      "Epoch 921/1000\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 18478.0103 - val_loss: 33583.1598\n",
      "Epoch 922/1000\n",
      "1137/1137 [==============================] - 1s 485us/step - loss: 18579.2332 - val_loss: 35919.0772\n",
      "Epoch 923/1000\n",
      "1137/1137 [==============================] - 1s 446us/step - loss: 19025.7944 - val_loss: 33150.4327\n",
      "Epoch 924/1000\n",
      "1137/1137 [==============================] - 0s 419us/step - loss: 18522.8880 - val_loss: 34264.8070\n",
      "Epoch 925/1000\n",
      "1137/1137 [==============================] - 0s 439us/step - loss: 18484.2334 - val_loss: 34161.9261\n",
      "Epoch 926/1000\n",
      "1137/1137 [==============================] - 1s 453us/step - loss: 17857.0125 - val_loss: 34730.9272\n",
      "Epoch 927/1000\n",
      "1137/1137 [==============================] - 0s 429us/step - loss: 18641.3493 - val_loss: 37381.9354\n",
      "Epoch 928/1000\n",
      "1137/1137 [==============================] - 0s 436us/step - loss: 18293.6445 - val_loss: 33499.2559\n",
      "Epoch 929/1000\n",
      "1137/1137 [==============================] - 0s 439us/step - loss: 18323.9034 - val_loss: 34463.1307\n",
      "Epoch 930/1000\n",
      "1137/1137 [==============================] - 1s 450us/step - loss: 18094.4863 - val_loss: 32971.1612\n",
      "Epoch 931/1000\n",
      "1137/1137 [==============================] - 1s 469us/step - loss: 18482.1527 - val_loss: 34108.4292\n",
      "Epoch 932/1000\n",
      "1137/1137 [==============================] - 0s 425us/step - loss: 18011.9152 - val_loss: 34444.1375\n",
      "Epoch 933/1000\n",
      "1137/1137 [==============================] - 1s 462us/step - loss: 18747.5624 - val_loss: 34446.7495\n",
      "Epoch 934/1000\n",
      "1137/1137 [==============================] - 1s 451us/step - loss: 18585.4059 - val_loss: 32792.1412\n",
      "Epoch 935/1000\n",
      "1137/1137 [==============================] - 0s 423us/step - loss: 17726.7204 - val_loss: 34194.7522\n",
      "Epoch 936/1000\n",
      "1137/1137 [==============================] - 0s 439us/step - loss: 18250.6022 - val_loss: 33730.9934\n",
      "Epoch 937/1000\n",
      "1137/1137 [==============================] - 0s 382us/step - loss: 18196.4497 - val_loss: 34190.6655\n",
      "Epoch 938/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 19597.6194 - val_loss: 35677.0376\n",
      "Epoch 939/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 18663.5184 - val_loss: 33667.5792\n",
      "Epoch 940/1000\n",
      "1137/1137 [==============================] - 0s 398us/step - loss: 19760.6104 - val_loss: 34694.2762\n",
      "Epoch 941/1000\n",
      "1137/1137 [==============================] - 0s 405us/step - loss: 18236.7517 - val_loss: 34145.1727\n",
      "Epoch 942/1000\n",
      "1137/1137 [==============================] - 0s 415us/step - loss: 18201.5932 - val_loss: 34499.4099\n",
      "Epoch 943/1000\n",
      "1137/1137 [==============================] - 1s 452us/step - loss: 18401.4676 - val_loss: 33670.6242\n",
      "Epoch 944/1000\n",
      "1137/1137 [==============================] - 1s 448us/step - loss: 18369.4413 - val_loss: 33870.3763\n",
      "Epoch 945/1000\n",
      "1137/1137 [==============================] - 0s 431us/step - loss: 17943.1726 - val_loss: 33247.0653\n",
      "Epoch 946/1000\n",
      "1137/1137 [==============================] - 0s 435us/step - loss: 18554.7065 - val_loss: 35059.4078\n",
      "Epoch 947/1000\n",
      "1137/1137 [==============================] - 0s 400us/step - loss: 19228.8939 - val_loss: 35214.2231\n",
      "Epoch 948/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 18040.313 - 0s 391us/step - loss: 17942.2335 - val_loss: 34077.1508\n",
      "Epoch 949/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: 18243.5392 - val_loss: 33401.5595\n",
      "Epoch 950/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 17993.1320 - val_loss: 33472.7687\n",
      "Epoch 951/1000\n",
      "1137/1137 [==============================] - 0s 390us/step - loss: 17450.5499 - val_loss: 34041.0942\n",
      "Epoch 952/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 18597.8743 - val_loss: 33541.8196\n",
      "Epoch 953/1000\n",
      "1137/1137 [==============================] - 0s 439us/step - loss: 18322.4281 - val_loss: 33824.6087\n",
      "Epoch 954/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 18498.9883 - val_loss: 34376.8208\n",
      "Epoch 955/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 19408.8644 - val_loss: 33976.1448\n",
      "Epoch 956/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 17590.1406 - val_loss: 33747.1896\n",
      "Epoch 957/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 18288.0511 - val_loss: 35410.0397\n",
      "Epoch 958/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 18113.1569 - val_loss: 35119.0831\n",
      "Epoch 959/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 18273.9306 - val_loss: 34222.4629\n",
      "Epoch 960/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 18472.4408 - val_loss: 33923.7277\n",
      "Epoch 961/1000\n",
      "1137/1137 [==============================] - 1s 479us/step - loss: 17771.8725 - val_loss: 33570.1901\n",
      "Epoch 962/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 17676.1375 - val_loss: 33415.6232\n",
      "Epoch 963/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 18300.5275 - val_loss: 37280.7081\n",
      "Epoch 964/1000\n",
      "1137/1137 [==============================] - 0s 389us/step - loss: 18333.3947 - val_loss: 34520.8819\n",
      "Epoch 965/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 17961.4927 - val_loss: 33741.8546\n",
      "Epoch 966/1000\n",
      "1137/1137 [==============================] - 0s 381us/step - loss: 18124.0524 - val_loss: 33582.8100\n",
      "Epoch 967/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 18057.1737 - val_loss: 33694.2386\n",
      "Epoch 968/1000\n",
      "1137/1137 [==============================] - 0s 375us/step - loss: 18038.6230 - val_loss: 33188.4878\n",
      "Epoch 969/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 18251.7782 - val_loss: 33996.6281\n",
      "Epoch 970/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 18561.851 - 0s 389us/step - loss: 18472.3624 - val_loss: 34150.2427\n",
      "Epoch 971/1000\n",
      "1137/1137 [==============================] - 0s 416us/step - loss: 18664.0655 - val_loss: 34419.0514\n",
      "Epoch 972/1000\n",
      "1137/1137 [==============================] - 0s 386us/step - loss: 17752.1920 - val_loss: 33902.5113\n",
      "Epoch 973/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: 17984.6743 - val_loss: 37936.2324\n",
      "Epoch 974/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 18833.1099 - val_loss: 33561.3014\n",
      "Epoch 975/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: 18417.3366 - val_loss: 33365.8466\n",
      "Epoch 976/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: 18242.5923 - val_loss: 34099.6949\n",
      "Epoch 977/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 18130.8629 - val_loss: 33770.7445\n",
      "Epoch 978/1000\n",
      "1137/1137 [==============================] - 0s 395us/step - loss: 18098.2643 - val_loss: 32707.5190\n",
      "Epoch 979/1000\n",
      "1137/1137 [==============================] - 0s 414us/step - loss: 17865.3359 - val_loss: 35404.2553\n",
      "Epoch 980/1000\n",
      "1137/1137 [==============================] - 0s 438us/step - loss: 17634.5457 - val_loss: 35981.0677\n",
      "Epoch 981/1000\n",
      "1137/1137 [==============================] - 0s 439us/step - loss: 18797.2694 - val_loss: 35208.4882\n",
      "Epoch 982/1000\n",
      "1137/1137 [==============================] - 0s 409us/step - loss: 17907.1594 - val_loss: 33411.0045\n",
      "Epoch 983/1000\n",
      "1137/1137 [==============================] - 0s 411us/step - loss: 17836.7486 - val_loss: 32765.1863\n",
      "Epoch 984/1000\n",
      "1137/1137 [==============================] - 1s 450us/step - loss: 17393.6168 - val_loss: 33601.4014\n",
      "Epoch 985/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 395us/step - loss: 18281.6279 - val_loss: 38856.0770\n",
      "Epoch 986/1000\n",
      "1137/1137 [==============================] - 0s 399us/step - loss: 18480.9297 - val_loss: 33035.3254\n",
      "Epoch 987/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 17839.4350 - val_loss: 32940.6427\n",
      "Epoch 988/1000\n",
      "1137/1137 [==============================] - 0s 403us/step - loss: 18139.6519 - val_loss: 35711.3650\n",
      "Epoch 989/1000\n",
      "1137/1137 [==============================] - 0s 419us/step - loss: 17738.2438 - val_loss: 32818.2169\n",
      "Epoch 990/1000\n",
      "1137/1137 [==============================] - 0s 439us/step - loss: 18194.2851 - val_loss: 33852.4224\n",
      "Epoch 991/1000\n",
      "1137/1137 [==============================] - 0s 413us/step - loss: 18352.4732 - val_loss: 35621.7111\n",
      "Epoch 992/1000\n",
      "1137/1137 [==============================] - 0s 435us/step - loss: 17732.1480 - val_loss: 34097.2313\n",
      "Epoch 993/1000\n",
      "1137/1137 [==============================] - 0s 433us/step - loss: 17552.8311 - val_loss: 33627.2466\n",
      "Epoch 994/1000\n",
      "1137/1137 [==============================] - 0s 423us/step - loss: 17792.0510 - val_loss: 33734.8067\n",
      "Epoch 995/1000\n",
      "1137/1137 [==============================] - 0s 416us/step - loss: 18109.9843 - val_loss: 34349.6295\n",
      "Epoch 996/1000\n",
      "1137/1137 [==============================] - 0s 414us/step - loss: 18250.3335 - val_loss: 32856.9775\n",
      "Epoch 997/1000\n",
      "1137/1137 [==============================] - 0s 432us/step - loss: 17625.9307 - val_loss: 34483.6200\n",
      "Epoch 998/1000\n",
      "1137/1137 [==============================] - 1s 449us/step - loss: 17797.0903 - val_loss: 35521.8347\n",
      "Epoch 999/1000\n",
      "1137/1137 [==============================] - 0s 430us/step - loss: 17848.2519 - val_loss: 33420.9355\n",
      "Epoch 1000/1000\n",
      "1137/1137 [==============================] - 0s 439us/step - loss: 17640.5286 - val_loss: 32870.4203\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
